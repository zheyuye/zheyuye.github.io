---
title: 'Literature Review of Query Reformulation'
date: 2021-01-28
permalink: /literature_review_of_query_reformulation
tags:
  - NLP
  - Survey

---

åœ¨å¤šè½®å¯¹è¯é—®ç­”, ç«¯åˆ°ç«¯å¯¹è¯èŠå¤©æœºå™¨äººç­‰å¤šä¸ªåœºæ™¯ä¸‹, ä¸å®Œæ•´çš„å¥å­åœ¨ç°æœ‰æ¡†æ¶ä¸‹çš„å¤„ç†æ˜¾å¾—å°¤ä¸ºæ£˜æ‰‹.  å¥å­çš„ä¸å®Œæ•´æ€§å¯ä»¥ä½“ç°åœ¨1. **æŒ‡ä»£è¯(coreference)**, ä½¿å¾—è¯­å¥è¯­ç„‰ä¸è¯¦æŒ‡ä»£ä¸æ¸…, æ²¡æ³•åœ¨ä¸Šä¸‹æ–‡ç¼ºå¤±çš„æƒ…å†µä¸‹å°±å•ä¸€å¥å­ç†è§£å«ä¹‰ 2. **çœç•¥è¯(ellipsi)**, å¯¼è‡´å¥å­æˆä»½ç¼ºå¤±, ä¸Šä¸‹æ–‡èƒŒæ™¯ä¿¡æ¯ä¸å®Œå–„. å¦‚ä½•è§£å†³è¿™ä¸¤ä¸ªé—®é¢˜ä¹Ÿå¼•å‘äº†å­¦ç•Œä¸šç•Œçš„å¹¿æ³›ç ”ç©¶æ¢è®¨, ä»è€Œè¡ç”Ÿå‡ºä¸¤ä¸ªå­ä»»åŠ¡**Coreference Resolution**å’Œ**Information Completion**. ä¸Šè¿°ä¸¤ä¸ªå­ä»»åŠ¡å¯ä»¥ç»Ÿç§°ä¸º**Incomplete Utterance Rewriting (IUR**), ç›®çš„æ˜¯å°†ä¸å®Œæ•´çš„è¯è¯­æ”¹å†™æˆè¯­ä¹‰ç­‰ä»·ä½†ç‹¬ç«‹äºè¯­å¢ƒçš„è¯è¯­. è¿™ç¯‡æ–‡çŒ®ç»¼è¿°é€‰å–äº†è¿‘å¹´æ¥æ¯”è¾ƒæœ‰ä»·å€¼çš„**ä¸€äº›(23ç¯‡)**ç›¸å…³å·¥ä½œ, åšäº†ç®€è¦æ¢³ç†, åŒ…æ‹¬ç›¸å…³å…¬å¼€æ•°æ®é›†, æ¨¡å‹æ„é€ æ–¹æ³•, etc.

## Contents

[toc]

##  [EMNLP 2019] Can You Unpack That? Learning to Rewrite Questions-in-Context (Elgohary et al., 2019)

å…³æ³¨äºè§£å†³Question Answerä»»åŠ¡ä¸­çš„Coreferenceå’ŒEllipsi, å¼•å…¥äº†åŸºäºä¸Šä¸‹æ–‡çš„é—®é¢˜æ”¹å†™ä»»åŠ¡ (**Task of question-in-context rewriting**), æ–‡ä¸­åˆç§°de-contextualization

> We introduce the task of question-in-context rewriting: given the context of a conversationâ€™s history, rewrite a context-dependent into a selfcontained question with the same answer.

ä»QuACæ•°æ®é›†ä¸­æå–äº†40,527ä¸ªquestions, æ„é€ äº† **C**ontext **A**bstraction: **N**ecessary **A**dditional **R**ewritten **D**iscourse [(CANARD) æ•°æ®é›†]( [https://sites.google.com/view/qanta/projects/canard](https://sites.google.com/view/qanta/projects/canard)).

ä»ä¸‹è¡¨ä¸­å¯ä»¥åˆ°äººç±»å¯¹æ¨¡å‹è¡¨ç°çš„å¯¹æ¯”(BLEU scores), è¿™ä»ç„¶æ˜¯ä¸€ä¸ªéš¾åº¦è¾ƒé«˜ä¸”å€¼å¾—å»æ¢ç´¢çš„ä»»åŠ¡.

<img src="https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210129003301053.png" alt="image-20210129003301053" style="zoom:70%;" />

## [COLING 2016] Non-sentential Question Resolution using Sequence to Sequence Learning (Kumar and Joshi, 2016)

è¿™ç¯‡2016å¹´çš„æ–‡ç« æŒ‡å‡ºQuestion Answering (QA) system å½“ä¸­non-sentential (incomplete) çš„é—®é¢˜. ç„¶è€Œä¸Šä¸‹æ–‡ç¼ºå¤±çš„æƒ…å†µä¸‹è¿™äº›é—®é¢˜å¾ˆéš¾è¢«é—®ç­”ç³»ç»Ÿå¾ˆå¥½çš„ç†è§£, å› æ­¤éœ€è¦QA systemå€ŸåŠ©å†å²å¯¹è¯æ•°æ®æ¥è¿˜åŸè¿™äº›**non-sentential utterances (NSU)**, ä»è€Œå¯ä»¥æ›´å¥½åœ°ç†è§£ç”¨æˆ·çš„æ„å›¾.  

å®éªŒæ•°æ®é›†æ— è®ºåœ¨å½“æ—¶è¿˜æ˜¯ç°åœ¨çœ‹æ¥éƒ½æ˜¯æ¯”è¾ƒå°çš„, åªåŒ…å«äº†7220æ®µå¯¹è¯, å…¶ä¸­æ¯æ®µå¯¹è¯åŒ…å«å…ˆå‰çš„é—®é¢˜(Q1), å…ˆå‰çš„ç­”æ¡ˆ (A1), NSU question (Q2), and æ”¹å†™åçš„å¥å­ (R1), å¦‚ä¸‹å›¾æ‰€ç¤º:

![image-20210201205938212](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210201205938212.png)

æ¨¡å‹å±‚é¢, ä½¿ç”¨äº†RNN-based encoder-decoder ç½‘ç»œç»“æ„, å¹¶åˆ†åˆ«è®¾è®¡äº†**Syntactic Sequence Model**å’Œ**Semantic Sequence Model**æ¥å­¦ä¹ è¯­è¨€å’Œè¯­ä¹‰è¡¨å¾ä¿¡æ¯, å¹¶é€šè¿‡ä¸€ä¸ªé›†æˆæ¨¡å‹é€‰å–ä¸Šè¿°ä¸¤ä¸ªæ¨¡å‹çš„è¾“å‡ºåºåˆ—ä¸­ä¸å¾…æ”¹å†™é—®é¢˜**å…³é”®å­—é‡åˆåº¦æœ€é«˜**çš„ä¸€ä¸ªä½œä¸ºç»“æœ.

**Syntactic Sequence Model** : 

å°½ç®¡è®­ç»ƒè¯­æ–™å¾ˆå°, ä½†æ˜¯å­—å…¸å¤§å°çš„é‡çº§ä»ç„¶ç»´æŒåœ¨10kå·¦å³, è¿™åœ¨RNN encoder-decoderç»“æ„ä¸‹éœ€è¦å¤§é‡çš„å‚æ•°æ¥ç»´æŠ¤ä¸€ä¸ªè¾“å‡ºå‘é‡, è¿™åœ¨ç®—åŠ›æœ‰é™çš„2016å¹´ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜. å¸¸è§çš„å¤„ç†æ–¹å¼æ˜¯, ç»´æŠ¤ä¸€ä¸ªè¾ƒå°çš„å­—å…¸å¤§å°, ç„¶åæŠŠæœªçŸ¥è¯éƒ½æ ‡è¯†ä¸ºUNK. 

Syntactic Sequence Modelå°†è¯­æ–™åº“ä¸­OOVçš„å•è¯æ›¿æ¢ä¸ºå¸¦æœ‰æ•°å­—ç¼–å·çš„UNK, è¿™ä¸ªæ•°å­—ç¼–å·æ˜¯å®ƒåœ¨å¯¹è¯ä¸­çš„ç›¸å¯¹ä½(å¦‚ä¸‹å›¾). symbols(UNK1, UNK2, UNK3, UNK4)åœ¨ä¸åŒå¯¹è¯å½“ä¸­æ˜¯å…±äº«çš„, è¿™ä½¿å¾—è¯¥æ¨¡å‹èƒ½å¤Ÿåœ¨ä¸åŒçš„å¯¹è¯ä¸­å­¦ä¹ è¯­è¨€ç»“æ„ä¿¡æ¯.  

![image-20210202163359796](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210202163359796.png)

**Semantic Sequence Model:** 

Syntactic Sequence Modelåªå…³æ³¨OOVè¯åœ¨åºåˆ—ä¸­çš„ä½ç½®ï¼Œåˆ†é…ä¸€ä¸ªæ–°çš„æœªçŸ¥ç¬¦å·UNKï¼Œå®Œå…¨æŠ›å¼ƒäº†OOVè¯ä¹‹é—´çš„è¯­ä¹‰ç›¸ä¼¼æ€§.  ä¸‹é¢è¿™ä¸ªä¸¤ä¸ªä¾‹å­(a) (b)ä¸­çš„UNKæ‹¥æœ‰å®Œå…¨ç›¸åŒçš„ä½ç½®, ä½†æ˜¯æ‰€æœŸæœ›å¾—åˆ°çš„R1å…¶å®æ˜¯å¤§ç›¸å¾„åº­çš„. 

![image-20210202163434481](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210202163434481.png)

å¯¹æ­¤, Semantic Sequence Modelçš„å¤„ç†æ–¹å¼æ˜¯, å°†UNKè¯é€šè¿‡word2Vecçš„ç»“æœè¿›è¡Œk-meansèšç±», ç”ŸæˆCategory Label(CL). ä¸Šè¿°(a)(b)ä¸¤ä¸ªä¾‹å­ä¸­çš„UNKçš„ç±»åˆ«åˆ†ç±»å¦‚ä¸‹

![image-20210202165217450](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210202165217450.png)

## [SIGIR 2017] Incomplete Follow-up Question Resolution using Retrieval based Sequence to Sequence Learning (Kumar and Joshi, 2017)

ä¸Šæ–‡çš„ä¸¤ä½ä½œè€…, åœ¨SIGIR 2017ä¹Ÿæœ‰åç»­çš„å·¥ä½œå±•ç°. å¥½åƒå¾ˆé‡è¦, æ‰¾ä¸åˆ°Access.

https://openreview.net/forum?id=Sy41ErWd-B

## [ACL 2016] Incorporating Copying Mechanism in Sequence-to-Sequence Learning (Gu et al., 2016)

ä½œè€…æ¥è‡ªé¦™æ¸¯å¤§å­¦å’Œåä¸ºè¯ºäºšæ–¹èˆŸå®éªŒå®¤. è¿™ç¯‡æ–‡ç« å‚è€ƒäº†äººç±»åœ¨å¯¹è¯å½“ä¸­å–œæ¬¢é‡å¤å¤è¿°åè¯å®ä½“å’Œè¾ƒé•¿çŸ­è¯­çš„å¤è¯»æœºè¡Œä¸º, æå‡ºäº†åŸºäºsequence-to-sequenceçš„COPYNETâ€‹, å¾ˆå¥½å¾—å°†ä¼ ç»Ÿçš„ç”Ÿæˆæ¨¡å¼å’Œæ‹·è´æ¨¡å¼é›†æˆåˆ°ä¸€èµ·. 

åœ¨NLPä¸­, sequence-to-sequenceè¿™æ ·çš„ç»å…¸æ¨¡å‹è¯•å›¾å°†ä»¥åŸå§‹è¯æ±‡è¡¨ç»„æˆçš„åŸå§‹åºåˆ—æ˜ å°„åˆ°ä¸€ä¸ªç›®æ ‡è¯æ±‡è¡¨ç»„æˆçš„ç›®æ ‡åºåˆ—ä¸­. åŸå§‹è¯æ±‡è¡¨å’Œç›®æ ‡è¯æ±‡è¡¨å¯ä»¥æ˜¯ç›¸åŒçš„, æˆ–è€…æœ‰å¾ˆå¤§ä¸€éƒ¨åˆ†æ˜¯é‡å çš„, å°±åƒæ–‡æœ¬æ‘˜è¦ä»»åŠ¡; ä¹Ÿå¯ä»¥æ˜¯å®Œå…¨ä¸åŒçš„, æ¯”å¦‚æœºå™¨ç¿»è¯‘åœºæ™¯ä¸‹. è¿˜æœ‰è®¸å¤šè¿™æ ·çš„ä»»åŠ¡éƒ½è¦æ±‚æ¨¡å‹èƒ½å¤Ÿåœ¨ç›®æ ‡åºåˆ—ä¸­äº§ç”Ÿå‡ºç°åœ¨æºåºåˆ—ä¸­, ä½†ç›¸å¯¹äºç›®æ ‡è¯æ±‡è¡¨è€Œè¨€out-of- vocabulary(OOV)çš„token. ä¸€ä¸ªç®€å•è€Œç›´è§‚çš„æƒ³æ³•å°±æ˜¯ç›´æ¥ä»åŸå§‹åºåˆ—å¤åˆ¶token, æ¥è§£å†³è¿™ä¸ªoové—®é¢˜.

**â€œcopy mechanismâ€**è¢«æ‹Ÿç”¨æ¥æ¨¡æ‹Ÿäººç±»æ²Ÿé€šäº¤æµè¿‡ç¨‹ä¸­â€œå¤è¿°â€çš„è¡Œä¸º, æ˜¯ä¸€ä¸ªé€‰æ‹©åŸå§‹åºåˆ—ä¸­çš„æŸä¸ªç‰‡æ®µï¼Œç„¶åå°†è¯¥ç‰‡æ®µæ‹·è´åˆ°ç›®æ ‡åºåˆ—ä¸­çš„è¿‡ç¨‹. 

**æ¨¡å‹æ„é€ : **

![image-20210129011938501](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210129011938501.png)

2021å¹´äº†, sequence-to-sequence, RNN,  Attention Mechanismè¿™äº›éƒ½è€ç”Ÿå¸¸è°ˆäº†, ä¸å†èµ˜è¿°äº†. 

CopyNetçš„å·¥ä½œæ–¹å¼æ˜¯åœ¨æ¯ä¸ªdecoding stepä¸­è®¡ç®—ç›®æ ‡è¯æ±‡è¡¨ä¸­çš„æ¯ä¸ªtokenå’Œæºåºåˆ—ä¸­çš„æ¯ä¸ªtokençš„æ¦‚ç‡ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼ŒCopyNetè·å¾—ä¸€ä¸ªç›®æ ‡è¯æ±‡è¡¨ä»¥åŠåŸå§‹åºåˆ—æ„æˆçš„**extended vocabulary**ï¼Œå…è®¸æ¨¡å‹æ½œåœ¨åœ°ç”Ÿæˆç›¸å¯¹ç›®æ ‡è¯æ±‡è¡¨OOVçš„token.  åœ¨CopyNetä¸­, Encoderé‡‡ç”¨äº†ä¸€ä¸ªBidi-RNNæ¨¡å‹, è¾“å‡ºä¸€ä¸ªéšè—å±‚$M$ä½œä¸ºshort-term memory; DecoderåŸºäºCanonical RNN-decoderæ”¹é€ , ä¸»è¦æœ‰ä»¥ä¸‹ä¸‰ç‚¹ä¸åŒ:

* Prediction: å­˜åœ¨ç”Ÿæˆæ¨¡å¼å’Œæ‹·è´æ¨¡å¼ä¸¤ç§ä¸åŒçš„è¯æ±‡è§£ç æ¨¡å¼ï¼ŒCopyNetçš„é¢„æµ‹åŸºäºè¿™ä¸¤ä¸ªæ¨¡å¼çš„æ··åˆæ¦‚ç‡æ¨¡å‹
* State Update: æ›´æ–°t-th stepçš„çŠ¶æ€æ—¶ï¼ŒCOPYNETä¸ä»…ä»…ä½¿ç”¨ç”¨t-1-th stepé¢„æµ‹ç»“æœçš„è¯å‘é‡ï¼Œè€Œä¸”ä½¿ç”¨Mä¸­ç‰¹å®šä½ç½®çš„hidden state
* Reading M: Copyneté€‰æ‹©æ€§åœ°è¯»å–Mçš„å€¼, è·å–å†…å®¹ä¿¡æ¯ä»¥åŠä½ç½®ä¿¡æ¯æœ‰æ•ˆæ··åˆä¿¡æ¯

æ‹“å±•è¯æ±‡è¡¨extended vocabularyå¯ä»¥å®šä¹‰ä¸º:

$$
\text{EV} = V \cup X \cup \text{[UNK]}
$$
å…¶ä¸­ç›®æ ‡è¯æ±‡è¡¨$V = \{v_â‚, \cdots , v_â‚™\}$ åŸå§‹åºåˆ—$X = \{x_â‚, \cdots , x_â‚™\}$ , æœªçŸ¥è¯ [UNK]. è¯¥æ¨¡å‹å°†èƒ½å¤Ÿåœ¨æ‹“å±•è¯æ±‡è¡¨ä¸­è‡ªç”±åœ°é€‰æ‹©è¯æ±‡ã€‚å…·ä½“è€Œè¨€, åœ¨è§£ç æ­¥éª¤çš„t-th step, token $y_t$çš„æ¦‚ç‡åˆ†å¸ƒä¸º:

$$
p\left(y_{t} \mid \cdot\right)=\underbrace{p_{g}\left(y_{t} \mid \cdot\right)}_{\text {generation prob. }}+\overbrace{p_{c}\left(y_{t} \mid \cdot\right)}^{\text {copy prob. }}
$$


![image-20210129014922886](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210129014922886.png)

æ ¹æ®ä¸Šå›¾çš„å››ç§æƒ…å†µ, åˆ†åˆ«è®¡ç®—generation probability $p_{g}\left(y_{t} \mid \cdot\right)$ å’Œcopy probability  $p_{c}\left(y_{t} \mid \cdot\right)$:

$$
p_{g}\left(y_{t} \mid \cdot\right)=\left\{\begin{array}{ll}\frac{1}{Z} e^{\psi_{g}\left(y_{t}\right)} & \text { if } y_{t} \in V \\ 0 & \text { if } y_{t} \in X \text { and } y_{t} \notin V \\ \frac{1}{Z} e^{\psi_{g}(U N K)} & \text { if } y_{t} \notin X \cup V
\end{array}\right.
$$

$$
p_{c}\left(y_{t} \mid \cdot\right)=\left\{\begin{array}{ll}\frac{1}{Z} \sum_{j: x_{j}=y_{t}} e^{\psi_{c}\left(x_{j}\right)} & \text { if } y_{t} \in X \\ 0 & \text { otherwise }\end{array}\right.
$$

å…¶ä¸­$Z=\sum_{v \in V \cup\{\mathrm{UNK}\}} e^{\psi_{g}(v)}+\sum_{j=1}^{m} e^{\psi_{c}\left(x_{j}\right)}$æ˜¯ä¸€ä¸ªnormalization term, $ \psi_{g}(\cdot)$æ˜¯generationçš„å¾—åˆ†å‡½æ•°,  $\psi_{c}(\cdot)$æ˜¯copyçš„å¾—åˆ†å‡½æ•°. 

**çŠ¶æ€æ›´æ–°**

t-1-th stepæ—¶åˆ», $y_{t-1}$çš„hidden stateè¡¨ç¤ºä¸º$\left[\mathbf{e}\left(y_{t-1}\right) ; \zeta\left(y_{t-1}\right)\right]^{\top}$, ç”±$y_{t-1}$çš„è¯å‘é‡ä¸çŠ¶æ€æƒé‡å’Œæ‹¼æ¥è€Œæˆ, ç†è§£ä¸º**attentive read** + **selective read**, weighted sum å‡½æ•°$\zeta(\cdot)$å®šä¹‰ä¸º:

$$
\begin{array}{l}\zeta\left(y_{t-1}\right)=\sum_{\tau=1}^{T_{S}} \rho_{t \tau} \mathbf{h}_{\tau} \\ \rho_{t \tau}=\left\{\begin{array}{ll}\frac{1}{K} p\left(x_{\tau}, \mathbf{c} \mid \mathbf{s}_{t-1}, \mathbf{M}\right), & x_{\tau}=y_{t-1} \\ 0 & \text { otherwise }\end{array}\right.\end{array}
$$

**Mçš„æ··åˆè§£æ**

ä¸€ä¸ªè¯çš„è¯­ä¹‰å’Œå®ƒåœ¨Xä¸­çš„ä½ç½®éƒ½å°†è¢«ä¸€ä¸ªç»è¿‡é€‚å½“è®­ç»ƒçš„ç¼–ç å™¨RNNç¼–ç åˆ°Mä¸­çš„éšè—çŠ¶æ€ä¸­ã€‚

åœ¨ç”Ÿæˆæ¨¡å¼ä¸‹, attentive readå æ®ä¸»å¯¼, å…¶ä¸»è¦ç”±å—åˆ°è¯­ä¹‰ä¿¡æ¯å’Œè¯­è¨€æ¨¡å‹æ¥é©±åŠ¨ï¼Œå› æ­¤é˜…è¯»Mä¸Šçš„ä¿¡æ¯æ—¶ä½ç½®æ›´åŠ è·³è·ƒè‡ªç”±; åœ¨æ‹·è´æ¨¡å¼ä¸‹ï¼Œå¯¹Mçš„selective readå¾€å¾€å—åˆ°ä½ç½®ä¿¡æ¯çš„å¼•å¯¼, ä»è€Œé‡‡å–**éè·³è·ƒå¼åƒµåŒ–ç§»åŠ¨(rigid move)**çš„åšæ³•, å¾€å¾€æ¶µç›–è¿ç»­çš„å¤šä¸ªè¯ï¼ŒåŒ…æ‹¬æœªçŸ¥è¯. 

ä½ç½®ä¿¡æ¯çš„æ›´æ–°æ–¹å¼å¦‚ä¸‹:

$$
\zeta\left(y_{t-1}\right) \stackrel{\text { update }}{\longrightarrow} \mathbf{s}_{t} \stackrel{\text { predict }}{\longrightarrow} y_{t} \stackrel{\text { sel. read }}{\longrightarrow} \zeta\left(y_{t}\right)
$$

## [ACL 2017] Get To The Point: Summarization with Pointer-Generator Networks (See  et  al.,  2017)

è®ºæ–‡åŸä½œè€…Abigail Seeçš„è§£è¯»: [http://www.abigailsee.com/2017/04/16/taming-rnns-for-better-summarization.html](http://www.abigailsee.com/2017/04/16/taming-rnns-for-better-summarization.html)

**Two Problems:**

åŸºäºRNN + attentionçš„abstractive summarizationæ–¹æ³•é¢ä¸´ä¸¤ä¸ªé—®é¢˜

1. æ²¡æ³•å‡†ç¡®åœ°å†ç°äº‹å®ç»†èŠ‚(**å¤åˆ¶æŸä¸ªè¯**), ç‰¹åˆ«é¢å¯¹oovæˆ–è€…ä¸å¸¸è§çš„è¯ 
   * rare wordsçš„word embeddingä¸å¤Ÿå¼º
   * ä¸€äº›åè¯æ€§è´¨çš„å•è¯å°½ç®¡æ‹¥æœ‰è¾ƒå¼ºçš„representation, ä½†æ˜¯å…¶embeddingå€¾å‘äºèšé›†åœ¨ä¸€èµ·ï¼Œè¿™å¯èƒ½ä¼šåœ¨è¯•å›¾è¿˜åŸå•è¯æ—¶é€ æˆæ··æ·†

2. ç»å¸¸è‡ªæˆ‘é‡å¤
   * decoderè¿‡åº¦ä¾èµ–äºå…¶è¾“å…¥, å³å…ˆå‰ç”Ÿæˆçš„è¯, è€Œä¸æ˜¯åœ¨decoderä¸­å­˜å‚¨é•¿ç¨‹ä¿¡æ¯

**How to Fix:**

**Easier Copying with Pointer-Generator Networks:** ä¸ºäº†è§£å†³**Problem 1** (inaccurate copying), æå‡ºäº†*pointer-generator network*. è¿™æ˜¯ä¸€ä¸ªæ··åˆç½‘ç»œï¼Œå¯ä»¥é€‰æ‹©é€šè¿‡pointä»åŸæœ¬å¤åˆ¶å•è¯ï¼ŒåŒæ—¶ä¿ç•™ä» fixed vocabularyç”Ÿæˆå•è¯çš„èƒ½åŠ›. å…·ä½“æ¨¡å‹æ„é€ å¯ä»¥æ¦‚æ‹¬ä¸ºè®¡ç®—attention distribution $a$, vocabulary distribution $P_\text{vocab}(w)$, generation probability $p_{\text{gen}} \in (0,1)$

$$
P_\text{final}(w) = p_{\text{gen}} P_\text{vocab}(w) + (1 - p_{\text{gen}})\sum_{i:w}^{i=w} a_i
$$

ç”Ÿæˆå•è¯wçš„æ¦‚ç‡ = ä»è¯æ±‡è¡¨ç”Ÿæˆçš„æ¦‚ç‡ + å¤åˆ¶åŸæ–‡æŸä¸€ä¸ªå¤„æ–‡æœ¬çš„æ¦‚ç‡

**Eliminating Repetition with Coverage**: ä¸ºäº†è§£å†³**Problem 2**(repetitive summaries), æå‡º*coverage*æ–¹æ³•ä½¿ç”¨attention distributionè®°å½•è¦†ç›–ç‡, ä¸ºé‡å¤éƒ¨åˆ†æ·»åŠ æƒ©ç½šæœºåˆ¶

$$
c_t =  \sum^{t-1}_{t\prime=0} a^{t\prime}
$$


å³, ä¸€ä¸ªåŸå§‹å•è¯çš„è¦†ç›–ç‡ç­‰äºå®ƒè¿„ä»Šæ‰€æ¥æ”¶åˆ°çš„attention scoresçš„å’Œ

## [ACL 2019] Improving Multi-turn Dialogue Modelling with Utterance ReWriter (Su  et  al.,  2019)

è¿™ç¯‡æ¥è‡ªå¾®ä¿¡äººå·¥æ™ºèƒ½æ¨¡å¼è¯†åˆ«ä¸­å¿ƒçš„æ–‡ç« , åˆ©ç”¨æŒ‡é’ˆç½‘ç»œå¼•å…¥äº†ä¸€ç§åŸºäºtransformerçš„é‡å†™ä½“ç³»ç»“æ„, åŒæ—¶å¦å¤–ä¸€å¤§è´¡çŒ®æ˜¯æ”¶é›†äº†ä¸€ä¸ªå¸¦æœ‰äººå·¥æ³¨é‡Šçš„æ–°æ•°æ®é›†.

**æ•°æ®é›†æ„é€ **

ä½œè€…ä»å‡ ä¸ªä¸»æµçš„ä¸­æ–‡ç¤¾äº¤åª’ä½“å¹³å°ä¸ŠæŠ“å–äº†200kä¸ªå€™é€‰çš„å¤šè½®ä¼šè¯æ•°æ®, ä»ä¸­æ•´ç†å‡ºäº†40kæ­£è´Ÿæ¯”ä¾‹å¹³è¡¡çš„é«˜è´¨é‡è¯­æ–™ï¼Œå…¶ä¸­æ­£ä¾‹æŒ‡åŒ…å«çœç•¥æˆ–æŒ‡ä»£, è´Ÿä¾‹ä¸­çš„å¥å­åˆ™æ‹¥æœ‰å®Œæ•´çš„è¯­ä¹‰è¡¨è¾¾, ä¸éœ€è¦é‡å†™. 

ä¸‹é¢è¿™å¼ è¡¨æ˜¯å…¶ä¸­éšæœº2000ä¸ªå¯¹è¯æ•°æ®ä¸­, çœç•¥oræŒ‡ä»£å‡ºç°é¢‘ç‡çš„åˆ†æç»“æœ.  åªæœ‰ä¸åˆ°30%çš„utterancesæ—¢æ²¡æœ‰æŒ‡ä»£ä¹Ÿæ²¡æœ‰çœç•¥ï¼Œç›¸å½“å¤šçš„utterancesäºŒè€…éƒ½æœ‰, è¿™è¿›ä¸€æ­¥è¯å®äº†åœ¨å¤šè½®å¯¹è¯ä¸­å¤„ç†æŒ‡ä»£å’Œçœç•¥çš„é‡è¦æ€§.

![image-20210128234324479](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210128234324479.png)

**æ¨¡å‹æ„é€ **

ä½¿ç”¨äº†åŸºäºTransformer encoder-decoderç»“æ„çš„copy network, è¯•å›¾æ ¹æ®å†å²å¯¹è¯æ•°æ®$H$ä»¥åŠéœ€è¦è¢«æ”¹å†™çš„æœ€åä¸€è½®utterances $U_n$ å­¦åˆ°ä¸€ä¸ªmapping function $p(R \mid (H, U_n ))$ ä»è€Œå¾—åˆ°æ”¹å†™åçš„å¥å­$R$. è·Ÿç»å…¸çš„Transformerç±»ä¼¼, å¯¹äºæ¯ä¸€ä¸ªtoken $w_i$ , å®ƒçš„è¯å‘é‡ç”±word embedding ä»¥åŠpositional embeddingç›¸åŠ å¾—åˆ°, å†æ¬¡åŸºç¡€ä¸Šæœ¬æ–‡å¼•å…¥äº†ç¬¬ä¸‰ç§embedding â€”â€”turn embedding ç”¨ä»¥åŒºåˆ†ä¸åŒè½®æ•°:

$$
I\left(w_{i}\right)=W E\left(w_{i}\right)+P E\left(w_{i}\right)+T E\left(w_{i}\right)
$$

<img src="https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210129011251221.png" alt="image-20210129011251221" style="zoom: 80%;" />

ä¸Šå›¾æ˜¾ç¤ºäº†æ¨¡å‹çš„æ•´ä½“æ¶æ„, Encoderå’ŒDecoderçš„éƒ¨åˆ†å‡ ä¹å°±æ˜¯typicalçš„Transformer, è¿™è¾¹ä¸å†èµ˜è¿°äº†. åœ¨æœ€ådecoderçš„è¾“å‡ºå±‚, æˆ‘ä»¬å¸Œæœ›æ¨¡å‹èƒ½åœ¨decodingé˜¶æ®µçš„æ¯ä¸€æ­¥éƒ½èƒ½å­¦ä¹ åˆ°æ˜¯å¦copyæ¥è‡ªå†å²å¯¹è¯æ•°æ®Hçš„å­—è¯. è¿™è¾¹ä¸€ä¸ªé¢å¤–çš„probability Î» éœ€è¦åœ¨æ¯ä¸€æ­¥è¢«è®¡ç®—æ¥å†³å®šæ˜¯å¦ä»context æˆ–è€…åŸå§‹å¾…æ”¹å†™å¥å­ $U_n$ä¸­å¤åˆ¶å­—è¯:

$$
\lambda=\sigma\left(\boldsymbol{w}_{d}^{\top} \mathbf{D}_{t}^{L}+\boldsymbol{w}_{H}^{\top} \mathbf{C}(H)_{t}^{L}+\boldsymbol{w}_{U}^{\top} \mathbf{C}\left(U_{n}\right)_{t}^{L}\right)
$$

* Î» = 1, If $U_n$ contains neither coreference nor information omission
* Î» = 0, when a coreference or omission is detected

é€šè¿‡maximizing $p(R \mid (H, U_n ))$ æ¥è®­ç»ƒè¿™ä¸ªç«¯åˆ°ç«¯æ¨¡å‹:

$$
p\left(R_{t}=w \mid H, U_{n}, R_{<t}\right)=\lambda \sum_{i:\left(w_{i}=w\right) \wedge\left(w_{i} \in \mathrm{H}\right)} a_{t, i} + (1-\lambda) \sum_{j:\left(w_{j}=w\right) \wedge\left(w_{j} \in U_{n}\right)} a_{t, j}^{\prime} \\ a=\operatorname{Attention}\left(\mathbf{M}^{(L)}, \mathbf{E}_{U_{n}}^{(L)}\right) \\ a^{\prime}=\operatorname{Attention}\left(\mathbf{M}^{(L)}, \mathbf{E}_{H}^{(L)}\right)
$$

$a$ and $a\prime$ åˆ†åˆ«æ˜¯Hå’Œ$U_n$çš„attention scores. æ­¤æ—¶æ³¨æ„æœºåˆ¶è´Ÿè´£ä»å¯¹è¯å†å²Hæˆ–è€…$U_n$ä¸­æ‰¾åˆ°é€‚å½“çš„å…±æŒ‡ä¿¡æ¯æˆ–ç¼ºçœä¿¡æ¯

**ç»“æœåˆ†æ: **

ä»¥ä¸‹å››ç§ä¸åŒç±»å‹çš„æ¨¡å‹æ¯”è¾ƒä¸­, T-Ptr-Genç”Ÿæˆè´¨é‡ä¸é«˜, æ¯”å•ç‹¬çš„Copy network(2)æ•ˆæœæ›´å·®

1. (L/T)-Gen: Pure generation-based model. Words are generated from **a fixed vocabulary.** (worst)
2. (L/T)-Ptr-Net: Pure **pointer-based** model. Words can only becopied from the input
3. (L/T)-Ptr-Gen: Hybrid **pointer+generation** model. Words can be either copied from the input or generatedfrom a fixed vocabulary.
4. (L/T)-Ptr-Î»: Our proposed model which split the attention by a coefficient Î».  (best)

## [EMNLP 2019] Improving Open-Domain Dialogue Systems via Multi-Turn Incomplete Utterance Restoration (Pan et  al.,  2019)

æ¥è‡ªè…¾è®¯AI Labçš„å·¥ä½œ, æ–‡ç« å¼€æºäº†ä¸€ä¸ªå¤§å‹å¤šè½®å¯¹è¯æ•°æ®é›†[Restoration-200K](https://ai.tencent.com/ailab/nlp/dialogue/#datasets), æå‡ºäº†**"pick-and-combine"**çš„æ–¹æ³•è¯•å›¾ä»å¯¹è¯ç³»ç»Ÿä¸­çš„ä¸Šä¸‹æ–‡å†…å®¹ä¸­è¿˜åŸä¸å®Œæ•´çš„è¯­å¥, å¹¶å¯¹æ¯”å…¶å’ŒSyntactic(Kumar and Joshi, 2016), Sequence-to-Sequence model (Seq2Seq)å’ŒPointer Generative Network (See  et  al.,  2017)çš„æ¨¡å‹è¡¨ç°.

**æ•°æ®é›†æ„é€ : **

åŸå§‹è¯­æ–™ä»è±†ç“£å°ç»„çˆ¬å–, æ•°æ®æ ·æœ¬å¤§å°ä¸º200k, å…¶ä¸­æ¯ä¸ªæ ·æœ¬ä¸­åŒ…å«6æ¡è¯­å¥. 

è¾›è‹¦çš„äº”äººæ ‡æ³¨å›¢é˜ŸèŠ±äº†å…­ä¸ªæœˆæ—¶é—´å®Œæˆäº†ä»¥ä¸‹ä¸¤ä¸ªæ ‡æ³¨ä»»åŠ¡:

1. utteranceæ˜¯å¦çœç•¥å…ˆå‰è¯è¯­ä¸­æ‰€äº§ç”Ÿçš„æ¦‚å¿µæˆ–å®ä½“, å³æ˜¯å¦éœ€è¦æ”¹å†™(ä¸ä¸Šæ–‡çš„æ­£è´Ÿæ ·æœ¬ç›¸åŒ)
2. å¯¹äºæ­£ä¾‹, äººå·¥é‡å†™ä¸å®Œæ•´çš„è¯­å¥. é‡å†™åçš„è¯­å¥è¢«è¦æ±‚å°½å¯èƒ½ä½¿ç”¨åŸæ–‡ä½¿ç”¨è¿‡çš„å­—è¯, æ¥å‡å°‘æ”¹å†™å¥å­çš„å¤šæ ·æ€§. å†è¿«ä¸å¾—å·²çš„æƒ…å†µä¸‹, å¯ä»¥ä½¿ç”¨é¢„å…ˆè®¾å®šå¥½çš„ä¸€ä¸ª**è§„æ¨¡è¾ƒå°çš„å¸¸ç”¨å•è¯åˆ—è¡¨**æ¥ä¿è¯å¥å­çš„æµç•…æ€§. åç»­æ ¡éªŒè¿‡ç¨‹å‘ç°åªæœ‰4.8%çš„å¥å­ä¸æ»¡è¶³è¿™ä¸ªè¦æ±‚, ä¸”éƒ½è¢«å‰”é™¤äºæ•°æ®é›†ä¹‹å¤–äº†.

<img src="https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210201200228749.png" alt="Statistics of Restoration-200K" style="zoom:80%;" />

ä»ä¸Šè¡¨çš„æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯ä¸­, æˆ‘ä»¬å¯ä»¥æ³¨æ„, è¿™200kå¤§å°çš„æ•°æ®é›†ä¸­æœ‰60%çš„å¥å­æ˜¯ä¸å®Œæ•´çš„. ç›¸æ¯”äºKumar and Joshi, 2016 (Avg. utterance lenght=3.52), Restoration-200Kçš„å¹³å‡è¯­å¥é•¿åº¦æ›´é•¿, ç†è®ºä¸Šå•å¥è¯åŒ…å«æ›´å¤šçš„ä¿¡æ¯.

**Pick-and-Combine(PAC) Model: **

ä½œè€…è¡¨ç¤º, è¿˜åŸåçš„utterancesä¸Original  utterancesçš„é‡å ç‡æ˜¯100%, è€Œä¸Previous utterancesçš„é‡å ç‡åªæœ‰17.7%. å› è€Œæ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­, ä¼šå€¾å‘äºç®€å•åœ°å¤åˆ¶åŸå§‹utterancesè€Œæ²¡æ³•æœ‰æ•ˆåœ°æ”¹å†™è¯¥è¯­å¥. PAC Modelå°†æ”¹å†™åˆ†ä¸ºäº†ä¸¤ä¸ªæ­¥éª¤

1. **Pick process**: ä½¿ç”¨BERT, è¯†åˆ«**Previous utterances**ä¸­è¢«çœç•¥çš„å•è¯ (åºåˆ—æ ‡æ³¨ä»»åŠ¡).
2. **Combine stage**:  æ ¹æ®å·²è¯†åˆ«çš„çœç•¥è¯æ¢å¤åŸè¯è¯­, å®éªŒéªŒè¯ä¸‹BERTæ•ˆæœä¸ä½³. å°†selected omitted wordsé™„åŠ åˆ°Original utterancesçš„åæ–¹, ç„¶åå°†è¿™ä¸¤ä¸ªåºåˆ—è¾“é€åˆ°ä¸€ä¸ªpointer generative networkä¸­.  (æ ‡æ³¨è¿‡ç¨‹ä¸­ä½¿ç”¨åˆ°çš„é¢å¤–å­—å…¸åœ¨è¿™è¾¹åº”è¯¥ä¹Ÿéœ€è¦å¼•å…¥è¿›æ¥, ç¡®ä¿PGNèƒ½å¤Ÿå°½å¯èƒ½åœ°è¿˜åŸrestored utterances)

![image-20210202155834750](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210202155834750.png)

æœºå™¨æŒ‡æ ‡å’Œäººå·¥æŒ‡æ ‡ä¸‹, PACéƒ½è¡¨ç°å‡ºäº†å“è¶Šçš„æ€§èƒ½è¡¨ç°.

<img src="https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210202170651315.png" alt="image-20210202170651315" style="zoom: 67%;" />

<img src="https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210202171237588.png" alt="image-20210202171237588" style="zoom:67%;" />

## [AAAI 2019] FANDA: A Novel Approach to Perform Follow-Up Query Analysis (Liu  et  al.,  2019a)

Slides: https://siviltaram.github.io/files/fanda-slides.pdf

åœ¨Natural Language Interfaces to Databases (NLIDB)åœºæ™¯ä¸­, ç”¨æˆ·å¯ä»¥ä½¿ç”¨è‡ªç„¶è¯­è¨€æœç´¢æ•°æ®åº“ï¼Œè€Œä¸æ˜¯ä½¿ç”¨ç±»ä¼¼sqlçš„æŸ¥è¯¢è¯­è¨€. ç„¶è€Œåœ¨ç”¨æˆ·å¤šè½®æŸ¥è¯¢çš„è¿‡ç¨‹ä¸­, ç»å¸¸å‡ºç°æç®€é—®, åç»­æŸ¥è¯¢(Follow-up query)ç­‰ç­‰ä¾‹å­, è¿™å°±éœ€è¦å……åˆ†è§£æä¸Šä¸‹æ–‡ä¿¡æ¯ä»è€Œç†è§£ç”¨æˆ·æŸ¥è¯¢çš„çœŸå®æ„å›¾. **Follow-up query**å¯ä»¥å®šä¹‰ä¸ºä¸Šä¸‹æ–‡æ— å…³é—®é¢˜(precedent query)çš„åç»­é—®é¢˜, å‰è€…æˆ‘ä»¬å¯ä»¥ç§°ä¹‹ä¸º**precedent query**, é‡å†™åèåˆä¸Šä¸‹æ–‡è¯­ä¹‰ä¿¡æ¯çš„queryåˆ™è¢«ç§°ä¸ºfused query.

ä»[WikiSQL](https://arxiv.org/abs/1709.00103)ä¸­ç­›é€‰äº†ä¸€ä¸ªæ•°æ®é›†[FollowUp](https://github.com/SivilTaram/FollowUp), å…¶ä¸­åŒ…å«äº†1000ä¸ªé—®é¢˜çš„ä¸‰å…ƒç»„è·¨è¶Š120ä¸ªä¸åŒçš„è¡¨, ä»¥ä¸‹æ˜¯ä¸€äº›æ•°æ®é›†ä¸­çš„æ ·æœ¬ç¤ºä¾‹. å¦å¤–ä¸€å¤§è´¡çŒ®åˆ™æ˜¯æå‡º**F**ollow-up **AN**alysis for **DA**tabases (FANDA)æ–¹æ³•

![image-20210202172908053](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210202172908053.png)

precedent query($x$)ä¸follow-up query($y$)å¾€å¾€ä¼šæœ‰å¤§é‡å†²çªçš„è¯­ä¹‰ç»“æ„. FANDAç‰¹æ­¤å°†symbol-levelå’Œsegment-levelä¸¤ç§ç»“æ„çš„ä¿¡æ¯éƒ½çº³å…¥è€ƒé‡, å‰è€…ä»£è¡¨å•è¯, åè€…ä»£è¡¨ä¸SQLè¯­å¥ç›¸å…³çš„çŸ­è¯­. å…·ä½“è€Œè¨€, FANDAçš„ç»“æ„å¯ä»¥ç»†åŒ–ä¸ºä¸‹å›¾æ‰€ç¤ºçš„ä¸‰ä¸ªæ¨¡å—:

<img src="https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210202190009315.png" alt="image-20210202190009315" style="zoom:80%;" />

**Anonymization**

è¿™ä¸€æ­¥éª¤ä¸­, queryå½“ä¸­çš„analysis-specific wordsä¼šè¢«æŒ–æ˜å‡ºæ¥.  Analysis-specific wordsæ˜¯SQLè¯­å¥çš„å…·ä½“å‚æ•°, å¯ä»¥åˆ†ä¸ºä¸‹å›¾å…«ç§. å¯ä»¥åœ¨FANDAçš„ç»“æ„å›¾ä¸­çœ‹åˆ°, è¿™å…«ç§analysis-specific wordsä¼šè¢«æ›¿æ¢ä¸ºå¯¹åº”çš„Symbol. è€Œå‰©ä¸‹æ˜¯ç»„æˆå¥å¼çš„ä¿®é¥°è¯(rhetorical words).

<img src="https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210202190638073.png" alt="image-20210202190638073" style="zoom:67%;" />

**Generation**

è¿™ç§æŒ–æ˜å­—è¯è¯­ä¹‰å´å¿½ç•¥äº†ä¸Šä¸‹æ–‡ä¿¡æ¯çš„è¡Œä¸º, è·ŸKumar and Joshi (2016)ä¸­çš„Semantic Sequence Modelæœ‰ç‚¹åƒ. ä¸ºäº†å¼¥è¡¥è¿™ç§ä¸Šä¸‹æ–‡è¯­ä¹‰ä¿¡æ¯çš„ç¼ºå¤±, segment structureè¢«ç”¨æ¥æ•æ‰è¿™äº›ä¿®é¥°è¯, é€šå¸¸åŸºäºSQLå‚æ•°å’Œç®€å•å¸¸è¯† (Table 3). åœ¨Generationä¸­, Symbolsè¢«ç»„åˆäº§ç”Ÿæ‰€æœ‰å¯èƒ½çš„segment sequences (è€ƒè™‘åˆ°ellipsisçš„å­˜åœ¨, å›¾ä¸€æœ‰12ç§å¯èƒ½), ç„¶åé€šè¿‡ä¸€ä¸ªranking modelæ¥é€‰æ‹©å¾—åˆ†æœ€é«˜çš„segment sequence. 

<img src="https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210202194231116.png" alt="image-20210202194231116" style="zoom:67%;" />

**Fusion**

Fusionæ¨¡å—å¯æ‹†åˆ†ä¸ºä¸¤æ­¥èµ°æˆ˜ç•¥:

1. ç¬¬ä¸€æ­¥: æ‰¾åˆ°xä¸yä¹‹é—´, sqlæˆä»½å†²çªçš„éƒ¨åˆ†(ç›¸åŒæˆ–ä¸å…¼å®¹çš„è¯­ä¹‰). 

2. ç¬¬äºŒæ­¥: æˆ‘ä»¬ç”¨ä¸€ä¸ªsegmentæ›¿æ¢å¦ä¸€ä¸ªsegmentæ¥èåˆä¸¤ä¸ªsegments, ä»¥è§£å†³ä¸Šè¿°å†²çª.

ç¬¬äºŒæ­¥ä¸­çš„"æ›¿æ¢"æ“ä½œå¯ä»¥å…·ä½“ä¸ºRefine å’Œ Append:

* Refine: â€œHow much money has Smith earned? How about Bill Collins?â€
* Append:  â€œHow much money has Smith earned? Compare with Bill Collins.â€

**Ranking model**

åŒºåˆ†ä¸¤ç§Intents: **Refine & Append**, å¹¶å‚ç…§NERçš„æ–¹æ³•, å¯¹Segè¿›è¡ŒIOBæ ‡æ³¨, BiDi-LSTM+CRFè¿›è¡Œranking , å–å¾—åˆ†æœ€é«˜çš„è¡¨è¾¾ä½œä¸ºæœ€åæ„å›¾. 

å¯¹äºsqlè¯­å¥çš„æ ‡æ³¨, è¿™æ˜¯ä¸€ä»¶æ¯•ç«Ÿè´¹æ—¶è´¹åŠ›çš„äº‹æƒ…, æœ¬æ–‡ä½¿ç”¨äº†å°‘é‡fused queryçš„ground truthè¿›è¡Œå¼±ç›‘ç£å­¦ä¹ . 

## [EMNLP 2019] A Split-and-Recombine Approach for Follow-up Query Analysis (Liu  et  al.,  2019b)

Slides: https://siviltaram.github.io/files/split-slides.pdf

code: https://github.com/microsoft/EMNLP2019-Split-And-Recombine

æ¥è‡ªä¸ä¸Šæ–‡å·¥ä½œçš„åŒä¸€æ‰¹ä½œè€…, inspired by è‡ªå·±ä¹‹ååˆæŠŠè‡ªå·±è¶…äº†ğŸ‘. æå‡ºäº†**S**pli**T**-And-**R**ecombine (STAR)æ¨¡å‹, æ­£å¦‚å…¶åå­—æ‰€æš—ç¤ºçš„, STARå…ˆå°†precedent query($x$)ä¸follow-up query($y$)æ‹†åˆ†ä¸ºå¤šä¸ªspan, ç„¶åå†é‡æ–°ç»„åˆåˆ°ä¸€èµ·ç”Ÿæˆrestated query(åˆæ¢äº†ä¸€ä¸ªåå­—), å¦‚ä¸‹å›¾æ‰€ç¤º:

![image-20210202202549973](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210202202549973.png)

![image-20210202203225934](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210202203225934.png)

è¦maximizeçš„ç›®æ ‡ä¸º:

$$
P_{\text {model }}(\mathbf{z} \mid \mathbf{x}, \mathbf{y})=\sum_{q \in \mathcal{Q}} P_{\text {split }}(q \mid \mathbf{x}, \mathbf{y}) P_{\text {rec }}(\mathbf{z} \mid q)
$$

å…¶ä¸­$\mathcal{Q}$ä¸ºsplit(x, y)çš„æ‰€æœ‰å¯èƒ½. ç”±äºç¼ºå°‘ç”¨äºsplittingå’Œrecombinationçš„æ³¨é‡Šï¼Œå¾ˆéš¾ç›´æ¥æ‰§è¡Œç›‘ç£å­¦ä¹ , å†è¿™è¾¹å¼ºåŒ–å­¦ä¹ å¤§æ³•åˆæ¥äº†:

$$
\mathcal{L}_{\mathrm{rl}}=\mathbb{E}\left[\sum_{\tilde{\mathbf{z}} \in \mathcal{Z}} \sum_{q \in \mathcal{Q}} P_{\mathrm{split}}(q \mid \mathbf{x}, \mathbf{y}) P_{\operatorname{rec}}(\tilde{\mathbf{z}} \mid q) r(\mathbf{z}, \tilde{\mathbf{z}})\right]
$$

å…¶ä¸­$\mathcal{Z}*$ æ˜¯æ‰€æœ‰restated  queryçš„å€™é€‰ç©ºé—´, $r$ä»£è¡¨ç”±æ¯”è¾ƒ$\mathbf{z}$å’Œæ ‡æ³¨$z$äº§ç”Ÿçš„reward.

**Phase I: Split**

æŠŠspanåˆ†å‰²ä»»åŠ¡å†å†å†å½“æˆåºåˆ—æ ‡æ³¨ä»»åŠ¡(Split or Retain). ä½¿ç”¨BiDAF (Seo et al., 2017)è·å–$x,y$ä¹‹é—´çš„è¯­ä¹‰äº¤äº’. Embeddingç”±character, word and sentenceæ‹¼æ¥è€Œæ¥: $\phi=\left[\phi_{c} ; \phi_{w} ; \phi_{s}\right]$

**Phase II: Recombine**

ç›´æ¥æˆ‘ä»¬åªéœ€å°†precedent queryä¸­çš„spanæ›¿æ¢ä¸ºfollow queryä¸­å†²çªçš„spanï¼Œä»¥ç”Ÿæˆrestated query.



æˆ‘ä»¬ç›´æ¥ç•¥è¿‡å¼ºåŒ–å­¦ä¹ çš„éƒ¨åˆ†ç›´æ¥çœ‹ç»“æœ:

<img src="https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210202201847378.png" alt="image-20210202201847378" style="zoom:80%;" />

## [NAACL 2018 Short] Higher-order coreference resolution with coarse-tofine inference (Lee et  al.,  2018)

Code: https://github.com/kentonl/e2e-coref/

è§£å†³é«˜é˜¶æŒ‡ä»£æ¶ˆè§£é—®é¢˜, ä¸»è¦æ˜¯globally inconsistentçš„é—®é¢˜:

<img src="https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210202211428782.png" alt="image-20210202211428782" style="zoom:80%;" />

**Baseline:** Bidirectional LSTMs
$$
s(i, j)=s_{\mathrm{m}}(i)+s_{\mathrm{m}}(j)+s_{\mathrm{a}}(i, j) \\ 
s_{\mathrm{m}}(i) =\boldsymbol{w}_{\mathrm{m}}^{\top} \mathrm{FFNN}_{\mathrm{m}}\left(\boldsymbol{g}_{i}\right) \\
s_{\mathrm{a}}(i, j) =\boldsymbol{w}_{\mathrm{a}}^{\top} \mathrm{FFNN}_{\mathrm{a}}\left(\left[\boldsymbol{g}_{i}, \boldsymbol{g}_{j}, \boldsymbol{g}_{i} \circ \boldsymbol{g}_{j}, \phi(i, j)\right]\right)
$$

æœ€åå¾—åˆ°antecedent distribution  $P\left(y_{i}\right)$

$$
P\left(y_{i}\right)=\frac{e^{s\left(i, y_{i}\right)}}{\sum_{y^{\prime} \in \mathcal{Y}(i)} e^{s\left(i, y^{\prime}\right)}}
$$

**Higher-order approach**

é«˜ç»´ä¿¡æ¯å…¶å®ä½“ç°åœ¨å¤šè½®å¯¹è¯ä¸­, ç®€å•åœ°ä½¿ç”¨LSTMè¿æ¥ä¸¤ä¸ªmentionä¼šå¯¼è‡´é•¿ç¨‹ä¿¡æ¯çš„æ¶ˆå¤±. è¿™ç¯‡æ–‡ç« æå‡ºäº†ä¸€ä¸ªæ¨ç†æ–¹æ³•, å……åˆ†è€ƒè™‘å‰æ–‡çš„ä¿¡æ¯. å…·ä½“è€Œè¨€æ˜¯å¤šè½®çš„è¿­ä»£(iterations), å‡è®¾Nè½®, é€šè¿‡attentionæœºåˆ¶å°†å‰ä¸€è½®çš„è¡¨å¾ä¿¡æ¯$g_j^{n-1}$åŠ å…¥è¿›æ¥, æ¥è®¡ç®—i,jä¸¤ä¸ªä½ç½®äº’ç›¸æ˜¯mentionçš„æ¦‚ç‡:

$$
P_{n}\left(y_{i}\right)=\frac{e^{s\left(\boldsymbol{g}_{i}^{n}, \boldsymbol{g}_{y_{i}}^{n}\right)}}{\sum_{y \in \mathcal{Y}(i)} e^{\left.s\left(\boldsymbol{g}_{i}^{n}, \boldsymbol{g}_{y}^{n}\right)\right)}}
$$

å…¶ä¸­$s$è¿˜æ˜¯baselineå½“ä¸­ç”¨åˆ°çš„å¾—åˆ†æ–¹ç¨‹. æ¯ä¸€è½®çš„span representation $g^n_i$çš„æ›´æ–°æ–¹å¼å¦‚ä¸‹:

$$
\begin{aligned}
\boldsymbol{f}_{i}^{n} &=\sigma\left(\mathbf{W}_{\mathrm{f}}\left[\boldsymbol{g}_{i}^{n}, \boldsymbol{a}_{i}^{n}\right]\right) \\
\boldsymbol{g}_{i}^{n+1} &=\boldsymbol{f}_{i}^{n} \circ \boldsymbol{g}_{i}^{n}+\left(\mathbf{1}-\boldsymbol{f}_{i}^{n}\right) \circ \boldsymbol{a}_{i}^{n}
\end{aligned}
$$

å…¶ä¸­$a_{i}^{n}=\sum_{y_{i} \in \mathcal{Y}(i)} P_{n}\left(y_{i}\right) \cdot g_{y_{i}}^{n}$

**Coarse-to-fine antecedent pruning**
ä¸Šè¿°æ¨ç†è¿‡ç¨‹æ¯”è¾ƒè€—æ—¶, éœ€è¦åŠ å…¥ä¸€äº›å‰ªææŠ€å·§. å¼•å…¥ä¸€ä¸ªalternate bilinearçš„å¾—åˆ†å‡½æ•°$s_{\mathrm{c}}(i, j)=g_{i}^{\top} \mathbf{W}_{\mathrm{c}} g_{j}$, $s_c(i,j)$ç›¸è¾ƒäº $s_a(i,j)$è®¡ç®—é‡è¦å°å¾—å¤š. è¿™æ ·æˆ‘ä»¬å¯ä»¥å°† $s(i,j)$æ”¹å†™ä¸º
:
$$
s(i, j)=s_{\mathrm{m}}(i)+s_{\mathrm{m}}(j)+s_{\mathrm{c}}(i, j)+s_{\mathrm{a}}(i, j)
$$

é€šè¿‡ä¸‰ä¸ªæ­¥éª¤, åˆ†åˆ«å¾—åˆ°

1. $s_{\mathrm{m}}(i)$çš„top M
2. $s_{\mathrm{m}}(i)+s_{\mathrm{m}}(j)+s_{\mathrm{c}}(i, j)$çš„top K
3. $s(i, j)$çš„top 1

## [EMNLP 2019 Short] BERT for Coreference Resolution: Baselines and Analysis (Joshi  et  al.,  2019)

ä¸€ç¯‡å°†BERTåº”ç”¨åˆ°Coreference Resolutionçš„å·¥ä½œ, æ°å¦‚å…¶å. åˆ†åˆ«å°†ä¸Šæ–‡ä¸­c2f-c2fcore (Lee et  al.,  2018)ä¸­çš„LSTMæ›¿æ¢ä¸ºBERT, Elmoå¯¹æ¯”äº†æ¨¡å‹è¡¨ç°. e2e-corefä¸ºä¸ä½¿ç”¨åˆ†å¸ƒå¼è¯­ä¹‰çš„æ¨¡å‹ç‰ˆæœ¬.

<img src="https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210202214753196.png" alt="image-20210202214753196" style="zoom:80%;" />

å› ä¸ºmax segment lençš„å­˜åœ¨, å¯¹äºè¶…è¿‡max segment lençš„æ–‡æ¡£, é‡‡ç”¨ä»¥ä¸‹ä¸¤ç§å˜ä½“ä½œä¸ºå¤„ç†æ–¹æ¡ˆ:

**Independent:** è¶…è¿‡max segment lenå°±æˆªæ–­

**Overlap:** è¶…è¿‡max segment lençš„æ–‡æ¡£, é€šè¿‡æ»‘åŠ¨çª—å£çš„å½¢å¼ç”Ÿæˆå¤šä¸ªç‰‡æ®µ. å†é€šè¿‡$f$æ‹¼æ¥èµ·æ¥:

$$
\begin{array}{l}
\mathrm{f}=\sigma\left(\mathrm{w}^{T}\left[\mathrm{r}_{1} ; \mathrm{r}_{2}\right]\right) \\
\mathrm{r}=\mathrm{f} \cdot \mathrm{r}_{1}+(1-\mathrm{f}) \cdot \mathrm{r}_{2}
\end{array}
$$

## [EMNLP 2020] Incomplete Utterance Rewriting as Semantic Segmentation (Liu  et  al.,  2020)

å°†incomplete utterance rewritingè½¬åŒ–ä¸ºä¸€ä¸ªè¯­ä¹‰åˆ†å‰²ä»»åŠ¡(Semantic Segmentation), æ„é€ ä¸€ä¸ªword-level edit matrix $Y = M \times N$ åŒ…å«ä¸‰ç§ä¸åŒçš„ç¼–è¾‘ç±»å‹: None, Substitute and Insert. æå‡ºäº†Rewritten U-shaped Network (RUN)æ¥æ„é€ è¿™ä¸ª$Y$, å¹¶è¿›è¡Œéšåçš„å­—è¯æ›¿æ¢æ’å…¥æ“ä½œ.

![image-20210129011502979](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210129011502979.png)

æ­£å¦‚ä¸Šå›¾æ¨¡å‹æ¶æ„æ‰€æç»˜çš„, æ¨¡å‹(RUN)ä¸»è¦ç”±ä»¥ä¸‹ä¸‰ä¸ªç»„ä»¶æ„æˆ:

* **Context layer:** GloVe  + BiLSTM (c and x are jointly encoded)
* **Encoding layer (concentrate on local rather than global information):**  concatenating 1. element-wise similarity (Ele Sim.) 2. cosine similarity (Cos Sim.) and  3. learned bi-linear similarity (Bi-Linear Sim.) -> D-dimensional feature vector $ F \in \R^{M \times N \times D}$
* **Segmentation layer (To capture global information):**  Conv + pool + skip connect + ffn ->  $ Y \in \R^{M \times N}$

ä¸Šè¿°æ¶æ„åŒæ ·å¯ä»¥ä½¿ç”¨åŸºäºé¢„è®­ç»ƒæ¨¡å‹(e.g. BERT, etc)è·å–åˆ†å¸ƒå¼è¡¨å¾ä¿¡æ¯, RUN + BERTè¡¨ç°å‡ºç›¸è¾ƒRUNæ›´æœ‰è¯´æœåŠ›çš„å®éªŒç»“æœ

ç”Ÿæˆå‰éœ€è¦è¿›è¡Œä¸€æ­¥standardizationç¡®ä¿æ‰€æœ‰çš„$Y$éƒ½æ˜¯é•¿æ–¹å½¢, based on Hoshenâ€“Kopelman, å¹¶æ·»åŠ **Connection Words**ä¿è¯å¥å­æµç•…åº¦

![image-20210128191115163](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210128191115163.png)

åœ¨REWRITERæ•°æ®é›† (Su  et  al.,  2019)ä¸Šçš„ç»“æœ:

![image-20210204144752188](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210204144752188.png)

## [EMNLP 2019] Unsupervised Context Rewriting for Open Domain Conversation (Zhou et  al.,  2019)

æå‡ºäº†**Context rewriting network (CRN)**, CRNåŸºäº Bidi-GRU + attentionçš„encoder-decoderæ¨¡å‹æ¶æ„å®ç°, åœ¨decodingé˜¶æ®µä½¿ç”¨CopNetæ¶æ„ä»åŸæ–‡ä¸­å¤åˆ¶æ–‡æœ¬. åœ¨æ²¡æœ‰çœŸå®æ ‡æ³¨çš„æ¡ä»¶ä¸‹, CRN model å…ˆåœ¨Pseudo Dataè¿›è¡Œé¢„è®­ç»ƒ, åœ¨ç”Ÿæˆé˜¶æ®µä¹Ÿ**å…³å¿ƒResponseä¸æ”¹å†™è¯­å¥çš„äº¤äº’å…³ç³»**, è¿›è€Œæé«˜å›å¤çš„å‡†ç¡®ç‡.

**æ¨¡å‹æ„é€  **

åœ¨Decoderå½“ä¸­, æ¯ä¸€ä¸ªstep $t$æ¥å—èåˆåçš„å¤šå…ƒä¿¡æ¯context $c$, last utterance $q$ä»¥åŠä¸Šä¸€æ­¥çš„hidden state $s_t$ä½œä¸ºè¾“å…¥, ä»è€Œæƒè¡¡æ˜¯å¦éœ€è¦ç›´æ¥ä»contextä¸­æ‹·è´å­—è¯åˆ°pseudo rewritten candidate $q^*$

$$
z_{t}=W_{f}^{T}\left[s_{t} ; \sum_{i=1}^{n q} \alpha_{q_{i}} h_{q_{i}} ; \sum_{i=1}^{n c} \alpha_{c_{i}} h_{c_{i}}\right]+b
$$

å…¶ä¸­$\alpha_q$, $\alpha_c$éƒ½æ˜¯æ³¨æ„åŠ›æƒé‡, æ ¹æ®ä»¥ä¸‹å…¬å¼è®¡ç®—å¯å¾—:

$$
\alpha_{i}=\frac{\exp \left(e_{i}\right)}{\sum_{j=1}^{n} \exp \left(e_{j}\right)} \\
e_{i}=h_{i} W_{a} s_{t}
$$

æœ€åå¯ä»¥ç”¨copy mechanismæ¥é¢„æµ‹ä¸‹ä¸€ä¸ªç›®æ ‡è¯æ±‡, æ ¹æ®è¿™ä¸ªæ¡ä»¶æ¦‚ç‡å…¬å¼:

$$
p\left(y_{t} \mid s_{t}, H_{Q}, H_{C}\right) =p_{p r}\left(y_{t} \mid z_{t}\right) \cdot p_{m}\left(\operatorname{pr} \mid z_{t}\right) + p_{c o}\left(y_{t} \mid z_{t}\right) \cdot p_{m}\left(c o \mid z_{t}\right) \\
L_{M L E}=-\frac{1}{N} \sum_{i=1}^{n} \log \left(p\left(y_{t} \mid s_{t}, H_{Q}, H_{C}\right)\right)
$$

$y_t$**æ˜¯å›å¤ä¸­çš„t-thè¯**,  $p_{pr}(y_t \mid z_t)$å’Œ$p_{co}(y_t \mid z_t)$åˆ†åˆ«æ˜¯predict-modeå’Œcopy-modeçš„å€™é€‰è¯æ¦‚ç‡åˆ†å¸ƒ, $\phi_{pr}(\cdot)$ å’Œ$\phi_{co}(\cdot)$åˆ†åˆ«æ˜¯å…¶å¾—åˆ†å‡½æ•°. å¹¶ä¸”ç”±ä¸€ä¸ªé¢å¤–çš„$p_m(\cdot \mid \cdot)$æ¥æ§åˆ¶é€‰æ‹©è¿™ä¸¤ä¸ªæ¨¡å¼çš„æ¦‚ç‡

$$
p_{m}\left(p r \mid z_{t}\right)=\frac{e^{\psi_{p r}\left(y_{t}, H_{Q}, H_{C}\right)}}{e^{\psi_{p r}\left(y_{t}, H_{Q}, H_{C}\right)}+e^{\psi_{c o}\left(y_{t}, H_{Q}, H_{C}\right)}}
$$

**Pre-training with Pseudo Data:**

å› ä¸ºæ•°æ®é›†ä¸­å¹¶æ²¡æœ‰æ”¹å†™å¥çš„æ ‡æ³¨ï¼Œå› æ­¤ä½œè€…ä»å¯¹è¯å†å²ä¸­æŠ½å–å…³é”®è¯æ¥æ„é€ æ¨¡æ‹Ÿæ•°æ®. 

**Key Words Extraction:** ä¸ºäº†å¯»æ‰¾å…±åŒä¿¡æ¯é‡å¤§çš„words, ä½œè€…ä½¿ç”¨äº†**pointwise mutual information (PMI)**æ¥æŠ½å–æ–‡æœ¬ä¸­çš„å…³é”®è¯

$$
\operatorname{PMI}\left(w_{c}, w_{r}\right)=-\log \frac{p_{c}\left(w_{c}\right)}{p\left(w_{c} \mid w_{r}\right)}
$$

$w_c$ æ˜¯context wordï¼Œ$w_r$ æ˜¯response word. ä¸ºäº†é€‰æ‹©å¯¹å›å¤æ¥è¯´æœ€é‡è¦çš„è¯ï¼Œä½œè€…ä¹Ÿè®¡ç®—äº†$\operatorname{PMI}\left(w_{c}, w_{q}\right)$, $w_q$æ˜¯last utteranceçš„è¯, æœ€ç»ˆçš„PMIåˆ†æ•°ä¸º

$$
\operatorname{PMI}\left(w_{c}, q\right)=\sum_{w_{q} \in q} \operatorname{PMI}\left(w_{c}, w_{q}\right) \\ 
\operatorname{PMI}\left(w_{c}, q, r\right) = \operatorname{norm}\left(\operatorname{PMI}\left(w_{c}, q\right)\right)+\operatorname{norm}\left(\operatorname{PMI}\left(w_{c}, r\right)\right)
$$

ç„¶åé€‰æ‹©PMIåˆ†æ•°æœ€é«˜çš„20%è¯æ’å…¥last utterance q. 

**Pseudo Data Generation:** åœ¨ç”Ÿæˆé˜¶æ®µ, æ¯ä¸€ä¸ªå…³é”®å­—å‰å2ä¸ªä½ç½®çš„ä¸´è¿‘è¯éƒ½è¢«è€ƒè™‘ä½œä¸ºæ’å…¥è¯. åœ¨å¦‚ä½•é€‰æ‹©æ’å…¥ä½ç½®è¿™ä¸ªé—®é¢˜ä¸Š, è¯­è¨€æ¨¡å‹å¤šå±‚RNNè¢«é€‰æ‹©ä½œä¸ºè§£å†³æ–¹æ¡ˆ, åŒæ—¶ä¿ç•™å¾—åˆ†æœ€é«˜çš„ä¸‰ä¸ªç”Ÿæˆå¥. è¿™ä¸‰ä¸ªç”Ÿæˆå¥è¢«è¾“é€åˆ°ä¸€ä¸ªencoder-decoderçš„ç”Ÿæˆæ¨¡å‹$M_{s2s}$ä»¥åŠä¸€ä¸ªå›å¤é€‰æ‹©æ¨¡å‹$M_{ir}$å½“ä¸­:

$$
L_{M_{s 2 s}}\left(r \mid s^{*}\right)=-\frac{1}{n} \sum_{i=1} \log p\left(r_{1}, \ldots, r_{n} \mid s^{*}\right)\\
L_{M_{i r}}\left(p o, n e, s^{*}\right)=M_{i r}\left(p o, s^{*}\right)-M_{i r}\left(n e, s^{*}\right)
$$

$r$æ˜¯å€™é€‰å›å¤, $q_r$æ˜¯CRNç”Ÿæˆçš„å€™é€‰query, ä»¥åŠpseudo rewritten candidate $q^*$

**Fine-Tuning with Reinforcement Learning:**

é€šè¿‡ä¸Šè¿°æ–¹å¼å¾—åˆ°çš„pseudo dataä¸å¯é¿å…çš„åŒ…å«ä¸€å®šç¨‹åº¦çš„é”™è¯¯å’Œå¹²æ‰°, ä¸ºäº†ä½¿å¾—å›å¤æ›´åŠ æµç•…, å¼•å…¥å¼ºåŒ–å­¦ä¹ æ¥åŠ å¼ºCRNæ¨¡å‹. å¯¹äºç”Ÿæˆåçš„æ”¹å†™è¯­å¥å€™é€‰å¥$q_r$, è®¡ç®—

å›å¤ç”Ÿæˆçš„å¥–åŠ±: 

$$
R_{g}\left(r, q^{*}, q_{r}\right)=L_{M_{s 2 s}}\left(r \mid q^{*}\right)-L_{M_{s 2 s}}\left(r \mid q_{r}\right)
$$

å›å¤é€‰æ‹©çš„å¥–åŠ±:   

$$
R_{i r}\left(p o, n e, q^{*}, q_{r}\right) =L_{M_{i r}}\left(p o, n e, q_{r}\right) - L_{M_{i r}}\left(po, ne, q^{*}\right)
$$

é…åˆç»å…¸çš„policy gradientç®—æ³•, è®¡ç®—RL objectiveçš„æŸå¤±å‡½æ•°

$$
\nabla_{\theta} J(\theta)=E\left[R \cdot \nabla \log \left(P\left(y_{t} \mid x\right)\right)\right]
$$

æœ€åæŠŠMLE loss å’ŒRL lossçš„å’Œä½œä¸ºæœ€åçš„è®­ç»ƒç›®æ ‡:

$$
L_{c o m}=L_{r l}^{*}+\lambda L_{M L E}
$$

## [ACL 2020] CorefQA: Coreference Resolution as Query-based Span Prediction (Wu  et  al.,  2020)

é¦™æµ“ç§‘æŠ€å®˜æ–¹çŸ¥ä¹æ–‡ç« :[https://zhuanlan.zhihu.com/p/126544790](https://zhuanlan.zhihu.com/p/126544790)

**Overall:**

æŠŠæŒ‡ä»£æ¶ˆè§£é—®é¢˜è½¬æ¢ä¸ºä¸€ä¸ªquery-based Spané¢„æµ‹é—®é¢˜, like Extractive QA Task â€” Query: ä¸€ä¸ªåŸºäºç›¸åº”ä»£è¯å‘¨å›´ä¸Šä¸‹æ–‡ç”Ÿæˆçš„é—®é¢˜, Answer: ä¸€ä¸ªClustersåŒ…å«æ‰€æœ‰ç›¸åŒæŒ‡ä»£å«ä¹‰çš„Coreferences.

1. è¿™ä¸ªspan predictionç­–ç•¥åœ¨mention proposal stageå…·æœ‰å¾ˆå¼ºçš„çµæ´»æ€§ï¼Œå¯ä»¥æ£€ç´¢å‡ºé—æ¼çš„mention; é¿å…mentioné—æ¼é€ æˆé”™è¯¯ä¼ é€’
2. ç”¨queryæ˜ç¡®åœ°å»encoding the mentionå’Œå®ƒçš„contextï¼Œè¿™æ ·é€šè¿‡MRCè®­ç»ƒæ¡†æ¶ä»¥åŠattentionæœºåˆ¶èƒ½å¤Ÿå°†ä¸Šä¸‹æ–‡çš„å½±å“ä¼ æ’­åˆ°æ¯ä¸€ä¸ªè¾“å…¥è¯ä¸­, ä»è€Œæ·±å…¥é€å½»åœ°ç†è§£coreferent mentionçš„context
3. å¤§é‡ç°æœ‰çš„MRCæ•°æ®é›†(SQuAD etc)å¯ç”¨äºæ•°æ®å¢å¼ºï¼Œä»¥æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›

**æ¨¡å‹æ„é€ :**

è¯¥æ¨¡å‹ç”±ä¸€ä¸ª**æŒ‡ç§°æå–æ¨¡å—(Mention Proposal)**å’Œä¸€ä¸ª**æŒ‡ç§°é“¾æ¥æ¨¡å—(Mention Linking)**ç»„æˆï¼Œ

**Mention Proposal:** ä½¿ç”¨FFNNä»åŸå§‹æ–‡æœ¬ä¸­æå–å‡ºæ‰€æœ‰å¯èƒ½çš„æŒ‡ä»£è¯ Mention, è·å¾—$e_i$çš„æŒ‡ç§°å¾—åˆ†:

$$
s_{\mathrm{m}}(i)=\mathrm{FFNN}_{\mathrm{m}}\left(\left[x_{\mathrm{FIRST}(i)}, x_{\mathrm{LAST}(i)}\right]\right)
$$

åœ¨å¾—åˆ°æ‰€æœ‰æ–‡æ®µçš„å¾—åˆ†ä¹‹åï¼Œåªå–å‰$\lambda N$ä¸ªä½œä¸ºå€™é€‰æŒ‡ç§°, Nä¸ºæ–‡æ¡£é•¿åº¦, $\lambda$ ä¸ºè¶…å‚æ•°.

**Mention Linking:** å°†æŒ‡ç§°èšç±»ä¸ºå…±æŒ‡è¯ â€” å¯¹å€™é€‰æŒ‡ç§°ä¸­çš„ä»»æ„ä¸€ä¸ªæŒ‡ç§°$e_i$, æŒ‡ç§°é“¾æ¥æ¨¡å—ä»»æ„ä¸€ä¸ªå…¶ä»–å€™é€‰æŒ‡ç§° $e_j$ï¼Œè®¡ç®—å®ƒä»¬æ˜¯å…±æŒ‡çš„å¾—åˆ†. æŠŠ$X$ä½œä¸ºä¸Šä¸‹æ–‡, $e_i$æ‰€åœ¨çš„å¥å­ä½œä¸ºquery $q(e_i)$,  $e_i$çš„æ‰€æœ‰coreferent mentionsä½œä¸ºAnswers $a$, å¾—åˆ°ä¸‰å…ƒç»„ \{context, query, answer\}. è€ƒè™‘åˆ°ä¸€ä¸ªmentionä¼šæœ‰å¤šä¸ªåŒ¹é…çš„coreferent mentions, **SpanBERT**è¢«ç”¨æ¥è·å–contextual representations ä»è€Œç»™$X$ä¸­çš„æ¯ä¸ª$x_i$ç”ŸæˆBIO tagging:

$$
p_{i}^{t a g}=\operatorname{softmax}\left(\mathrm{FFNN}_{\operatorname{tag}}\left(\boldsymbol{x}_{i}\right)\right)
$$

æŠŠtoken scoreæ‹“å±•åˆ°span scoreå¯ä»¥å¾—åˆ°$e_j$å¯¹$e_i$çš„å…±æŒ‡å¾—åˆ†

$$
s_{a}(j \mid i)=\frac{1}{\left|e_{j}\right|}\left[\log p_{\text {FIRST }(j)}^{B}+\sum_{k=\operatorname{FIRST}(j)+1}^{k=\mathrm{LAST}(j)} \log p_{\mathrm{k}}^{I}\right]
$$

æ ¹æ®å…¶å¯¹ç§°çš„åŒå‘å…³ç³», å¯ä»¥å¾—åˆ°$e_i$å’Œ$e_j$çš„å…±æŒ‡å¾—åˆ†$s_{a}(i, j)$

$$
s_{a}(i, j)=\frac{1}{2}\left(s_{a}(j \mid i)+s_{a}(i \mid j)\right)
$$

æœ€ç»ˆ$e_i$å’Œ$e_j$çš„å…±æŒ‡è¯å¾—åˆ†å¯ä»¥ç”±ä»¥ä¸‹ç­‰å¼è·å¾—

$$
s(i, j)=s_{m}(i)+s_{m}(j)+s_{a}(i, j)
$$

å³, ä»–ä»¬æ˜¯å…±æŒ‡çš„å‰ææ˜¯ 1)ä»–ä»¬åˆ†åˆ«æ˜¯mention 2)ä»–ä»¬äº’ç›¸æ˜¯coreferent mentions

## [NAACL 2019] Scaling Multi-Domain Dialogue State Tracking via Query Reformulation (Rastogi et  al.,  2019)

æ¥è‡ªAI Amazon Alexa AIçš„å·¥ä½œ, ä¸»è¦æ˜¯æƒ³è§£å†³å¤šè½®å¯¹è¯ä¸‹çš„å¯¹è¯çŠ¶æ€è·Ÿè¸ª(dialogue state tracking)ä»¥åŠæŒ‡ä»£æ¶ˆè§£é—®é¢˜(referring resolution tasks). åŒæ ·åœ°, æŠŠä»»åŠ¡é‡æ„ä¸ºè§£å†³åŸºäº**å¯¹è¯å†…å®¹è‡ªæ„ŸçŸ¥çš„è¯­å¥é‡å†™ä»»åŠ¡(dialogue context-aware user query reformulation task)**, ä¸‹å›¾æ˜¯ä¸€ä¸ªAmazon Alexaçš„å®é™…ä¾‹å­, CQR Engineå¯ä»¥å°†ç”¨æˆ·çš„è¾“å…¥"Buy his latest book" è½¬åŒ–ä¸º"But Yuval Harari's latest book." . åœ¨æ–‡ä¸­, pointer-generator network(PGN,  See  et  al.,  2017)åŒæ ·è¢«ä½¿ç”¨åˆ°, å¹¶ä¸”ä½¿ç”¨äº†multi-task learningæ¥è®­ç»ƒè¿™ä¸ªPGN, å¯ä»¥åšåˆ°åœ¨è®­ç»ƒä¸­**ä¸éœ€è¦é¢å¤–çš„äººå·¥æ ‡æ³¨æ•°æ®**.

<img src="https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210203195629925.png" alt="image-20210203195629925" style="zoom:80%;" />

è®¡ç®—PGNä¸­ä¸­çš„generation probability $p_{gen}\left(y_{t} \mid \cdot\right)$ å’Œcopy probability  $p_{copy}\left(y_{t} \mid \cdot\right)$ä»¥åŠä¸€ä¸ªæ¨¡å¼é€‰æ‹©æ¦‚ç‡$p^{mix} \in (0,1)$, æœ€åå¾—åˆ°è¾“å‡ºåˆ†å¸ƒ:

$$
p\left(y_{k}\right)=p^{\operatorname{mix}} p^{\mathrm{gen}}\left(y_{k}\right)+\left(1-p^{\operatorname{mix}}\right) p^{\operatorname{copy}}\left(y_{k}\right)
$$

åœ¨è®­ç»ƒæ•°æ®ä¸­, ç»´æŠ¤äº†ä¸€ä¸ªrewrites-corpus $\{x_{it}, y*_{itj}\}^{I,T,J}_{i=1,t=1,j=1}$ å…¶ä¸­i,t,jåˆ†åˆ«è¡¨ç¤ºï¼šç¬¬iä¸ªå¯¹è¯æ•°æ®ï¼ŒæŸä¸ªå¯¹è¯ä¸­çš„ç¬¬tè½®ï¼Œjè¡¨ç¤ºæ­£ç¡®æ”¹å†™ä¸­çš„ç¬¬jä¸ªæ”¹å†™(å¤šä¸ªgolden reference). è®­ç»ƒç›®æ ‡åˆ™æ˜¯ä¼˜åŒ–å¦‚ä¸‹log-likelihood:

$$
\arg \max _{\theta} \sum_{i, t, j, k} \log p_{\theta}\left(y_{i, t, j, k}^{*}\right)
$$

<img src="https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210203203401074.png" alt="image-20210203203401074" style="zoom: 67%;" />

ä¸Šé¢è¿™ä¸ªä¾‹å­ä¸­æˆ‘ä»¬å¯ä»¥çœ‹åˆ°, $y*_{t=2}$åŒ…å«ä¸¤ä¸ªgolden reference. å°½ç®¡ä»–ä»¬è¯­åºä»¥åŠæ‰€åŒ…å«çš„å­—è¯éƒ½ä¸ç›¸åŒ, ä½†æ˜¯Entity S1å’ŒU3éƒ½å‡ºç°å…¶ä¸­. è¿™æ„å‘³ç€ï¼Œå¯¹äºå¯¹è¯é‡å†™ä»»åŠ¡ï¼Œä»è¾“å…¥å¯¹è¯æ¡†å¤åˆ¶çš„å®ä½“å­é›†åº”è¯¥ä¿æŒä¸å˜ï¼Œè€Œä¸ç®¡decoder stateçš„åŠ¨æ€. ä¹Ÿå°±æ˜¯è¯´, å¯¹äºtask-orientedå‹è¯­å¥é‡å†™ä»»åŠ¡è¯­å¥æ”¹å†™åœºæ™¯ä¸‹, **å…³é”®å®ä½“ä¿¡æ¯**ä¸åº”è¯¥æœ‰ç¼ºå¤±. ä¸ºæ­¤, åŠ å…¥SLU(Spoken Language Understanding)æ¨¡å—è¯†åˆ«å‡ºæ¥çš„domainå’Œintentä¿¡æ¯, e.g. BOOKQUERYå’ŒSYSTEM INFORMINTENT.  æ­¤å¤–è¿˜éœ€è¦ä¸€æ­¥**å»è¯åŒ–(delexicalize)**æ“ä½œ: å³ç”¨è¯¥å®ä½“ç±»å‹æˆ–åç§°æ›¿æ¢æ‰å…·ä½“çš„å®ä½“value e.g. "Sapiens" -> "book".

![image-20210203205617506](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210203205617506.png)

Multi Task Learning (MTL)ä¸­, å¯ä»¥å¼•å…¥ä¸€ä¸ªé¢å¤–çš„**Entity-Copy Auxiliary Objective**ç”¨æ¥åˆ¤æ–­Inputä¸­çš„Entityæ˜¯å¦åœ¨golden rewritesä¸­. ç†è®ºä¸Šè¿™ä¸ªé¢å¤–çš„è®­ç»ƒç›®æ ‡ä¼šä¼˜åŒ–encoderäº§ç”Ÿçš„è¡¨å¾ä¿¡æ¯, ä½¿å…¶æ›´å…³æ³¨äºæ˜¯å¦copyè¿™ä¸ªentity. æœ€åçš„PGNçš„ç›®æ ‡å‡½æ•°å¦‚ä¸‹:

$$
\sum_{i, t, j, k} \log p\left(y_{i, t, j, k}^{*}\right)+\lambda \sum_{i, t} \sum_{l=1}^{\left|x_{i, t}\right|} e_{i, t, l} \log g_{\phi}\left(h_{i, t, l}\right)
$$

å…¶ä¸­$\lambda > 0$æ˜¯ä¸€ä¸ªè¶…å‚æ•°, $e_{i, t, l}$ä¸º

$$
e_{i, t, l}=
\left\{
\begin{aligned}
1 & \text { if } x_{i, t, l} \text { is an entity and } x_{i, t, l} \in \mathcal{Y}_{i, t}^{*} \\
-1 & \text { if } x_{i, t, l} \text { is an entity and } x_{i, t, l} \notin \mathcal{Y}_{i, t}^{*} \\
0 & \text { Otherwise }
\end{aligned}
\right.
$$

## [EMNLP 2019] GECOR: An End-to-End Generative Ellipsis and Co-reference Resolution Model for Task-Oriented Dialogue (Quan et  al.,  2020)

Code: https://github.com/terryqj0107/GECOR

Oral: https://vimeo.com/424412465

Web: https://multinlp.github.io/GECOR/

æå‡ºäº†**G**enerative Ellipsis and **CO**-reference **R**esolution model (GECOR), ä¸»è¦æ€æƒ³æ˜¯åœ¨ç”Ÿæˆæ¨¡å¼å’Œå¤åˆ¶æ¨¡å‹ä¹‹é—´åˆ‡æ¢æ¥ç”Ÿæˆä¸€ä¸ªè¯­ä¹‰å®Œå–„çš„è¯è¯­.  åˆæäº†ä¸€ä¸ªæ•°æ®é›†[CamRest676](https://multinlp.github.io/GECOR/), CamRest676æ•°æ®é›†åŒ…å«676ä¸ªå¯¹è¯ï¼Œæœ‰2744ä¸ªç”¨æˆ·è¯è¯­. è¿™2744ä¸ªç”¨æˆ·è¯è¯­ä¸­æœ‰1,174 ellipsis å’Œ1,209 Co-reference è¢«æ ‡æ³¨å‡ºæ¥. å‚è€ƒSu  et  al.,  2019çš„æ•°æ®åˆ†å‰²æ–¹æ¡ˆ, CamRest676åŒ…å«1,331 ä¸ªåŒ…å«ellipsisæˆ–co-referenceçš„æ­£ä¾‹, ä»¥åŠä¸éœ€è¦æ”¹å†™çš„è´Ÿä¾‹1413ä¸ª.

![image-20210203143933026](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210203143933026.png)

GECORä¸è€ƒè™‘ellipsisæˆ–co-referenceçš„è¯­æ³•ç‰¹æ€§, å®ƒä»¬å¯ä»¥æ˜¯å­—è¯, çŸ­è¯­ç”šè‡³çŸ­å¥. åŒæ—¶è¿™ç§æ”¹å†™æ–¹å¼ä¸éœ€è¦æä¾›ä¸€ç»„è¦è§£æçš„å€™é€‰æŒ‡ä»£, ä»¥å¾€çš„ç ”ç©¶, such as Lee et  al.,  2018å¾€å¾€éœ€è¦åœ¨å­˜åœ¨å¤šä¸ªellipsisæˆ–co-referenceçš„æƒ…å†µä¸‹éå†æ–‡æœ¬ï¼Œè®¡ç®—å¤æ‚åº¦è¾ƒé«˜ã€‚

embedding layeré‡‡ç”¨Glove, Utterance and Context Encoderè´Ÿè´£åˆ†åˆ«å¯¹å¾…æ”¹å†™å¥å­å’Œå¯¹è¯å†…å®¹è¿›è¡Œç¼–ç . åœ¨Decoderä¸­, éœ€è¦åˆ†åˆ«è®¡ç®—ä¸Gu et al., 2016ç±»ä¼¼çš„generation probability $p_{g}\left(y_{t} \mid \cdot\right)$ å’Œcopy probability  $p_{c}\left(y_{t} \mid \cdot\right)$:

**generation probability:** 
$$
\begin{array}{l}
P^{g}\left(y_{t}\right)=\frac{1}{Z} e^{\psi_{g}\left(y_{t}\right)}, \quad y_{t} \in \mathbf{V} \\
\psi_{g}\left(y_{t}=v_{i}\right)=\mathbf{v}_{i}^{T}\left(W_{g}^{h} h_{t}^{*}+W_{g}^{s} s_{t}+b_{g}\right) \\
s_{t}=\operatorname{GRU}\left(\left[y_{t-1} ; h_{t}^{*}\right], s_{t-1}\right)
\end{array}
$$

å…¶ä¸­$\mathbf{V}$ä¸ºentire vocabulary, $s_{t-1}$ä¸ºå‰ä¸€æ­¥decoder state, $y_{t-1}$æ˜¯å‰ä¸€æ­¥ç”Ÿæˆçš„word embedding, $Z$æ˜¯å½’ä¸€é¡¹.

**copy probability**

å¯¹äºdialogue contextä¸­çš„æ¯ä¸€ä¸ªè¯, æ˜¯å¦å°†å…¶æ‹·è´çš„æ¦‚ç‡$P^{c}(y_{t})$å¦‚ä¸‹:

$$
\begin{array}{l}
P^{c}\left(y_{t}\right)=\frac{1}{Z} \sum_{i: c_{i}=y_{t}}^{|\mathbf{C}|} e^{\psi_{c}\left(c_{i}\right)}, \quad y_{t} \in \mathbf{C} \\
\psi_{c}\left(y_{t}=c_{i}\right)=\sigma\left(W_{c} h_{i}^{c}+b_{c}\right) s_{t}
\end{array}
$$

$h_{i}^{c}$æ˜¯context encoderå¯¹äº$c_i$çš„è¾“å‡ºç»“æœ. 

å……åˆ†è€ƒè™‘ä¸Šè¿°ä¸¤ä¸ªæ¦‚ç‡, å¯ä»¥å¾—åˆ°åœ¨extended vocabulary = $\mathbf{V} \cup \mathbf{C}$ä¸Šçš„é€‰è¯æ¦‚ç‡åˆ†å¸ƒå…¬å¼ä¸º:

$$
P\left(y_{l}\right)=P^{g}\left(y_{\iota}\right)+P^{c}\left(y_{l}\right), y_{\iota} \in \mathbf{V} \cup \mathbf{C}
$$

ä¸Šè¿°copyæœºåˆ¶(Gu et al., 2016)å¯ä»¥æ›¿æ¢ä¸ºåŸºäºSee  et  al., (2017)ä¿®æ”¹è€Œæ¥çš„gated copy mechanism, å³å¼•å…¥ä¸€ä¸ª$p_{g e n} \in (0,1)$:

$$
\begin{array}{l}
p_{g e n}=\sigma\left(W_{h} h_{L}^{*}+W_{s} s_{\ell}+W_{y} y_{l-1}+b_{l}\right) \\
P\left(y_{l}\right)=p_{g e n} P^{g}\left(y_{l}\right)+\left(1-p_{g e n}\right) P^{c}\left(y_{l}\right)
\end{array}
$$

å°†GECORé›†æˆåˆ°ä¸€ä¸ªend-to-endçš„task-orientedå¯¹è¯ç³»ç»ŸTSCP ([Lei et al. 2018](https://www.aclweb.org/anthology/P18-1133/))å½“ä¸­. å¯ä»¥ä»ä¸‹å›¾ä¸­çœ‹åˆ°, è¿™ä¸ªend-to-endæ¶æ„, ä¸€å…±åŒ…å«2ä¸ªencoder (åˆ†åˆ«å¯¹user utteranceå’Œä¸Šä¸‹æ–‡è¿›è¡Œç¼–ç ), 3ä¸ªdecoders: ä¸€ä¸ªdecoderç”¨äºé¢„æµ‹å¯¹è¯çŠ¶æ€ï¼Œç¬¬äºŒä¸ªdecoderç”¨äºç”Ÿæˆå®Œæ•´çš„ç”¨æˆ·è¯è¯­ï¼Œç¬¬ä¸‰ä¸ªdecoderç”¨äºç”Ÿæˆç³»ç»Ÿå“åº”.

![image-20210203143958584](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210203143958584.png)

ç›®å‰åªå…³æ³¨GECORçš„ç»“æœ, æš‚æ—¶ä¸çœ‹TSCPçš„:

<img src="https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210203171548373.png" alt="image-20210203171259002" style="zoom:80%;" />

baseline model æ¥è‡ª [Zheng et al. (2018)](http://jcip.cipsc.org.cn/EN/abstract/abstract2686.shtml) çš„seq2seq neural network model.

## [AAAI 2020] Filling Conversation Ellipsis for Better Social Dialog Understanding (Zhang  et  al.,  2020)

å®˜æ–¹åšå®¢: https://xiyuanzh.github.io/projects/AAAI2020.html

Code and Data: https://gitlab.com/ucdavisnlp/filling-conversation-ellipsis

çœç•¥(ellipsis)ç°è±¡åœ¨æ—¥å¸¸å¯¹è¯å½“ä¸­ååˆ†å¸¸è§, ellipsisçš„å­˜åœ¨ä¹Ÿå¢åŠ äº†**å¯¹è¯è§’è‰²é¢„æµ‹(Dialog Act Prediction), è¯­ä¹‰è§’è‰²æ ‡æ³¨(Semantic Role Labeling)**ç­‰ä¸‹æ¸¸ä»»åŠ¡çš„éš¾åº¦. é€šå¸¸ä¼šé‡‡ç”¨è‡ªåŠ¨è¡¥å…¨çš„æ–¹æ³•æ¥å¡«å……ellipsis, ä½†æ˜¯è‡ªåŠ¨è¡¥å…¨çš„è¯è¯­å¯èƒ½ä¼šé‡å¤æˆ–é”™è¿‡ä¸€äº›å•è¯, ç”šè‡³å¯èƒ½äº§ç”Ÿæ— æ„ä¹‰çš„å¥å­. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ··åˆæ¨¡å‹**Hybrid-ELlipsis-CoMPlete (Hybrid-EL-CMP)**, å……åˆ†è€ƒé‡å¸¦æœ‰original utterance with ellipsisä»¥åŠè‡ªåŠ¨è¡¥å…¨çš„utterance, ä»¥æé«˜è¯­è¨€ç†è§£èƒ½åŠ›. 

<img src="https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210203140601052.png" alt="image-20210203140601052" style="zoom:80%;" />

è®©æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹ä¸Šè¡¨ä¸­çš„ç¬¬äºŒä¸ªä¾‹å­. ç”¨æˆ·åœ¨è¯´å®Œ"Okay"ä¹‹ååœé¡¿äº†ä¸€ä¸‹è¯´"Letâ€™s change conversation", å®é™…ä¸Šä»–çš„çœŸå®æ„å›¾æ˜¯æƒ³ç»“æŸå¯¹è¯. è€Œè‡ªåŠ¨è¡¥å…¨çš„User responseä¼šè®©ç³»ç»Ÿè¯¯ä»¥ä¸ºç”¨æˆ·è¡¨ç¤ºåŒæ„. æœ¬æ–‡æå‡ºçš„Hybrid-EL-CMPæ­£æ˜¯è¦è§£å†³automatically completed utteranceæ‰€äº§ç”Ÿçš„é”™è¯¯, ä»¥ä¾¿äºåœ¨ä¸‹æ¸¸çš„Dialog Act Predictionä¸è¯¯å¯¼ç”¨æˆ·æ„å›¾, ä»¥åŠSemantic Role Labelingä¸­èƒ½æ­£ç¡®æ ‡è¯†è¯­å¥æˆä»½. ä¸Šè¿°ä¸¤ä¸ªä¸‹æ¸¸ä»»åŠ¡, ä¹Ÿæ˜¯æœ¬æ–‡çš„evaluation tasks.  Hybrid-EL-CMPä½œä¸ºä¸€ç§è¾…åŠ©æ ¡éªŒæ¨¡å‹, å¯ä»¥ä¸ºä¸‹æ¸¸ä»»åŠ¡æä¾›æ›´å¥½çš„è¯­è¨€è¡¨è¾¾èƒ½åŠ›, ä½†æˆ‘ä»¬ç›®å‰æ›´å…³å¿ƒå¦‚ä½•è‡ªåŠ¨è¡¥å…¨ä¸å®Œæ•´çš„è¯è¯­.

## [ACL 2020] Generate, Delete and Rewrite: A Three-Stage Framework for Improving Persona Consistency of Dialogue Generation (Song et al., 2020)

è…¾è®¯AIåˆæ¥äº†, çœŸçš„é«˜äº§.

## [EMNLP 2020] Semantic role labeling guided multi-turn dialogue rewriter (Xu et al., 2020)

è…¾è®¯AIä¸‰æ€äº†.  è¿™ç¯‡æ–‡ç« æŒ‡å‡º, ä¸Šè¿°å‰åºå·¥ä½œçš„decoderä¸»è¦ä½¿ç”¨global attentionä»è€Œå…³æ³¨å¯¹è¯è¯­å¢ƒä¸­çš„æ‰€æœ‰å•è¯. ç”±äºæ²¡æœ‰é¢„å…ˆå¼•å…¥å…ˆéªŒç„¦ç‚¹(prior focus), ä¸Šè¿°atentionæœºåˆ¶çš„æ³¨æ„åŠ›å¯èƒ½ä¼šå¯¹ä¸€äº›æ— å…³ç´§è¦çš„å­—è¯å¸å¼•. å¾ˆè‡ªç„¶åœ°å¯ä»¥æƒ³åˆ°â€” ä½¿ç”¨**Semantic Role Labeling (SRL)**è¯†åˆ«å¥å­çš„**è°“è¯-å®å‚(Predicate-Argument)**ç»“æ„ï¼Œä»è€Œæ•è· ***who did what to whom***è¿™æ ·çš„è¯­ä¹‰ä¿¡æ¯ä½œä¸ºå…ˆéªŒè¾…åŠ©decoder. ä¸‹å›¾è¿™ä¸ªä¾‹å­å¾ˆå¥½åœ°ä½“ç°äº†è¯­ä¹‰æˆåˆ†åœ¨Utterenaceä¸­èµ·åˆ°çš„ä½œç”¨, â€œç²¤è¯­â€å’Œâ€œæ™®é€šè¯â€è¢«è¯†åˆ«ä¸ºä¸¤ä¸ªä¸åŒçš„å®å‚, å¯ä»¥åœ¨SRLçš„æŒ‡å¯¼ä¸‹è·å¾—æ›´å¤šçš„å…³æ³¨. 

<img src="https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210204014253359.png" alt="image-20210204014253359" style="zoom:80%;" />

è…¾è®¯AIçš„æ ‡æ³¨å›¢é˜Ÿä»Duconv[(Wu et al., 2019)](https://arxiv.org/abs/1906.05572)æ•°æ®é›†ä¸Š, æ ‡æ³¨äº†3000ä¸ª dialogue sessions, åŒ…å«33,673ä¸ªè°“è¯, 27,198ä¸ªè¯è¯­. é€‰ç”¨äº†ä¸€ä¸ª**é¢å¤–çš„**BERT-based SRL model [(Shi and Lin, 2019)](https://arxiv.org/abs/1904.05255)ä½œä¸ºSRL parserç”¨æ¥å®Œæˆè¿™ä¸ªè°“è¯-å®å‚ç»“æ„çš„è¯†åˆ«ä»»åŠ¡, å¹¶ä¸”åœ¨CoNLL 2012 (117,089 examples)è¿›è¡Œåˆæ­¥é¢„è®­ç»ƒ. 

![image-20210204142413045](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210204142413045.png)

Input Representationè¿˜æ˜¯BERTç»å…¸ä¸‰ä»¶å¥—Toekn Embedding, Segment Type Embeddingså’ŒPosition Embeddings, $E_A, E_B$ç”¨ä»¥åŒºåˆ†Speakers. Inputç”±PA structures, dialog context, and rewritten utteranceä¸‰è€…æ‹¼æ¥è€Œæˆ, å…¶ä¸­PA structuresç”±æœ¬è´¨ä¸Šçš„ä»¥è°“è¯ä¸ºæ ¹, è¯­ä¹‰å®å‚ä¸ºå¶å­çš„æ ¹è½¬ä¸ºæ¢<predicate, role, argument>çš„çº¿æ€§ä¸‰å…ƒç»„, å¹¶ä»¥éšæœºé¡ºåºæ‹¼æ¥.  è¿™æ ·ä»¥éšæœºé¡ºåºiæ‹¼æ¥çš„æœºåˆ¶å¯èƒ½ä¼šå¯¹sequence encoderå¸¦æ¥ä¸€å®šçš„å¹²æ‰°ä¿¡æ¯. è¿™è¾¹å¼•å…¥é™„åŠ åœ¨PA sequenceä¸Šçš„bidirectional attention maskæœºåˆ¶æ¥è¾…åŠ©, å³ä¸åŒPAä¸‰å…ƒç»„ä¸­çš„tokenä¸èƒ½ç›¸äº’attend. åŒæ—¶PAä¸‰å…ƒç»„çš„position embeddingä½¿ç”¨å„ä¸ªä¸‰å…ƒç»„çš„ç‹¬ç«‹ä½ç½®ä¿¡æ¯.

åœ¨REWRITE(Su  et  al.,  2019)æ•°æ®é›†ä¸Šè¿›è¡Œå®éªŒå¯¹æ¯”ä¸€ä¸‹ç»“æœ, BERTæŒ‡ä»£RoBERTa Chinese. **å¤ç°ç»“æœä¸Su  et  al.,  (2019)ä¸å¤ªä¸€è‡´.**

![image-20210204145330846](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210204145330846.png)

**Ablation Study:**

* SRL: æ¥è‡ªç»ç”±CoNLL 2012è®­ç»ƒçš„SRL parser, 75.66 precision, 74.47 recall, and 75.06 F1
  * Bi-mask: PA Triplesä¸­çš„tokenå¯ä»¥äº’ç›¸å…³æ³¨
  * Triple-mask: åªå…è®¸åœ¨åŒä¸€ä¸ªTripleçš„Tokenäº’ç›¸å…³æ³¨, ä¸åŒçš„Triplesä¸­çš„tokenå½¼æ­¤æ˜¯ä¸å¯è§çš„ -> ç‹¬ç«‹åœ°ç¼–ç æ¯ä¸ªè°“è¯-å‚æ•°ä¸‰å…ƒç»„ï¼Œè¿™å¯ä»¥é˜²æ­¢ä¸å¿…è¦çš„ä¸‰å…ƒå†…éƒ¨æ³¨æ„ï¼Œä»è€Œæ›´å¥½åœ°æ¨¡æ‹ŸSRLç»“æ„

* Partial-SRL: SRL Modelåªä½œç”¨äºå¾…æ”¹å†™å¥

* Gold-SRL: **ä½¿ç”¨SRLçš„golden labelä½œä¸ºè¾“å…¥**, è¯´æ˜SRL modelçš„è´¨é‡é«˜åº¦å½±å“rewriter.

åœ¨Restoration-200K(Pan et al., 2019)æ•°æ®é›†ä¸Šå®éªŒç»“æœå¦‚ä¸‹, è¿˜ä¸å¦‚Pan et al., (2019)æå‡ºçš„PAC Model.

<img src="https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210204150311732.png" alt="image-20210204150311732" style="zoom:80%;" />

> we find that the SRL information mainly improves the performance on the dialogues that require information completion. One omitted information is considered as properly completed if the rewritten utterance recovers the omitted words. We find the SRL parser naturally offers important guidance into the selection of omitted words

## [EACL 2021] Ellipsis Resolution as Question Answering: An Evaluation (Aralikatte et  al.,  2021)

æ–‡ç« æŠŠçœç•¥è¡¥å……é—®é¢˜å’ŒæŒ‡ä»£æ¶ˆè§£é—®é¢˜è½¬åŒ–ä¸ºQAé—®é¢˜, å¦‚ä¸‹queryå¯ä»¥è½¬åŒ–ä¸º<context, question, answer>çš„ä¸‰å…ƒç»„: 

* context: the entire document

* question: the sentence in which the ellipsis/mention is present

* answer:  the antecedent/entity 

å¯¹äºæŒ‡ä»£æ¶ˆè§£é—®é¢˜, å¦‚æœä¸€ä¸ªå¥å­åŒ…å«nä¸ªmentions, å°±è½¬ä¸ºæˆä¸ºnä¸ªquestionså…¶ä¸­resolutionç”¨<ref></ref>åŒ…è£¹.

P.S. Ellipsisè¢«åˆ†ä¸ºSluice Ellipsiså’ŒVerb Phrase Ellipsis, åˆ†åˆ«æœ‰ä¸åŒçš„å…¬å¼€æ•°æ®é›†.

<img src="https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210204000806314.png" alt="image-20210204000806314" style="zoom:80%;" />

**QA Architectures**

é€‰å–ä¸‰ç§ä¸åŒçš„encoder module:

1. DrQA (Chen et al., 2017), LSTM
2. QANet (Yu et al., 2018), CNN
3. BERT (Devlin et al., 2018), pre-trained Transformer 

ç®€å•çœ‹ä¸‹ç»“æœ:

<img src="https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210204003514239.png" alt="image-20210204003514239" style="zoom:80%;" />

å¾ˆå¥‡æ€ªè¿™ç¯‡æ–‡ç« æ²¡æœ‰è·Ÿcoreference taskçš„ä¸€äº›å·¥ä½œè¿›è¡ŒåŒå‘æ¯”è¾ƒ, ä»–ä»¬è¿™æ ·è§£é‡Š:

> In this section, we analyse the best performing coreference models and discuss why they cannot be compared with other works in literature.

## [WSDM 2021] Question Rewriting for Conversational Question Answering (Vakulenko et  al.,  2021)

æœ¬æ–‡å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨QRç»„ä»¶æ‰©å±•ç°æœ‰çš„SOTA QAæ¨¡å‹ï¼Œå¹¶æ¼”ç¤ºäº†æ‰€æå‡ºçš„æ–¹æ³•æé«˜äº†QAä»»åŠ¡åœ¨End-to-endä¼šè¯ä¸‹çš„æ€§èƒ½ã€‚é€šè¿‡QRç»„ä»¶é‡å†™è¯è¯­, å‡å°‘äº†follow-up questionsçš„æ¨¡ç³Šæ€§çš„ï¼Œä½¿å®ƒä»¬å¯ä»¥è¢«ç°æœ‰çš„QAæ¨¡å‹ä½œä¸ºå¯¹è¯ä¸Šä¸‹æ–‡ä¹‹å¤–çš„ç‹¬ç«‹é—®é¢˜æ¥å¤„ç†ã€‚

æå‡ºäº†åŸºäºTransformer++ä½œä¸ºQuestion Rewriting Model, å¹¶å°†å…¶åµŒå…¥äºä¸¤ç§ä¸åŒçš„QAä»»åŠ¡ç±»å‹ä¸­, å…³æ³¨ä¼šè¯åœºæ™¯ä¸‹QRä»»åŠ¡ä¸­åœ¨ä¸åŒç±»å‹QAæ¨¡å‹ä¸­çš„åº”ç”¨èƒ½åŠ›.

1. retrieval QA: å³åœ¨ç»™å®šçš„æ–‡ç« ä¸­, æ ¹æ®å·²æœ‰<é—®é¢˜, ç­”æ¡ˆ>åŒ¹é…å…³ç³»é›†åˆå¯»æ‰¾ç­”æ¡ˆ
2. extractive QA: å³åœ¨ä¸€ç¯‡æ–‡ç« ä¸­ä¸ºä¸€ä¸ªç»™å®šçš„è‡ªç„¶è¯­è¨€é—®é¢˜æ‰¾åˆ°ç­”æ¡ˆã€‚

ä¸»è¦è´¡çŒ®åœ¨äºåœ¨TREC CAsT 2019 passage retrieval datasetä»¥åŠCANARDæ•°æ®é›†ä¸Šè¿›è¡Œç›¸å…³å®éªŒ, å¯¹æ¯”äº†ç›¸å…³baseline:

![image-20210302132514070](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210302132514070.png)

## [ArXiv 2020] Robust Dialogue Utterance Rewriting as Sequence Tagging (Hao et  al.,  2020)

Paper Link: https://arxiv.org/abs/2012.14535

è¿™ç¯‡æ¥è‡ªXu et al., (2020)åŒä¸€ä¸ªå›¢é˜Ÿçš„æ–‡ç« æŒ‡å‡º, ä»å¯¹è¯å†…å®¹ä¸­æ‹·è´ç¼ºå¤±å†…å®¹æ¥é‡å†™è¯­å¥çš„æ–¹å¼å—é™äºä¸åŒDomain. æ–‡æœ¬ç”Ÿæˆéœ€è¦å¾€å¾€éœ€è¦å¯¹æ¯ä¸ªå­—è®¡ç®—output probability, è¿™å°±ä½¿å¾—æœç´¢ç©ºé—´éšç€å­—å…¸å¤§å°å’Œä¸Šä¸‹æ–‡å¯¹è¯é•¿åº¦çš„å¢åŠ è€Œæ‰©å¤§. æ­¤å¤–, æš´éœ²åå·®(exposure bias, Wisemanå’ŒRush, 2016)ä¼šè¿›ä¸€æ­¥åŠ å‰§æµ‹è¯•ç”¨ä¾‹ä¸è®­ç»ƒé›†ä¸ç›¸ä¼¼çš„é—®é¢˜ï¼Œå¯¼è‡´è¾“å‡ºä¸è¾“å…¥è¡¨è¾¾ä¸åŒçš„è¯­ä¹‰å«ä¹‰. æ–‡æœ¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„sequence-tagging-based modelæ¥è§£å†³è¿™ä¸€å¥å£®æ€§é—®é¢˜, ä½¿å¾—æœç´¢ç©ºé—´å¤§å¤§å‡å°‘. åŒæ—¶ä¸ºäº†è§£å†³ç¼ºä¹æµç•…æ€§è¿™ä¸€æ–‡æœ¬ç”Ÿæˆçš„æ ‡æ³¨æ¨¡å‹çš„é€šç—…, ä½œè€…åœ¨ä¸€ä¸ªREINFORCE frameworkä¸‹æ³¨å…¥æ¥è‡ªBLEUæˆ–GPT-2çš„æŸå¤±ä¿¡å·. 

**R~A~ST: Rewriting as Sequence Tagging:**

å…ˆå‰çš„å·¥ä½œå¾€å¾€å¯¹äºellipsiså’Œco-referenceé‡‡å–ä¸åŒçš„ç­–ç•¥, å¾€å¾€æ˜¯Insert, Repalce. R~A~STå°†Insertå’ŒRepalceè¿™ä¸¤ä¸ªæ“ä½œç”¨ä¸€ä¸ªå…ˆdeletionåInsetionçš„æ“ä½œä»£æ›¿. æ ‡æ³¨æ•°æ®ç”±longest common sub-sequence (LCS)ç®—æ³•ç”Ÿæˆ, å‰”é™¤REWRITE(Su  et  al.,  2019)å’ŒRESTORATION-200K(Pan et al., 2019ä¸­ä¸æ»¡è¶³è¦æ±‚çš„.

![image-20210204161459033](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210204161459033.png)

* Deletion  $\in \{0, 1\}$: the word $x_n$ is deleted (i.e. 1) or not (i.e. 0);
* Insertion: [start, end]: å¯¹è¯å†…å®¹ä¸­çš„ä½ç½®ä¿¡æ¯, If no phrase is inserted, the span is [-1, -1]. 

Insertionä¸­çš„span predictionå½“ä½œMRCå¤„ç†.

**Enhancing Fluency with Additional Supervision:**

REINFORCEçš„å¼ºåŒ–å­¦ä¹ ç›®æ ‡:

$$
\mathcal{L}_{r l}=\left(r\left(\hat{u}_{i}^{g}, u_{i}\right)-r\left(\hat{u}_{i}^{s}, u_{i}\right)\right) \log p\left(\hat{u}_{i}^{s} \mid X\right)
$$

å…¶ä¸­$\hat{u}_{i}^{g}$å’Œ$\hat{u}_{i}^{s}$åˆ†åˆ«æ¥è‡ªç”Ÿæˆå’Œé‡‡æ ·çš„candidate sentences, $r(\cdot, \cdot)$æ˜¯reward function æ¥è‡ªsentence-level BLEUæˆ–è€…GPT-2 model, å¯ä»¥å¾—åˆ°æœ€åçš„æŸå¤±å‡½æ•°:

$$
\mathcal{L}=(1-\lambda) \mathcal{L}_{\text {tagging }}+\lambda \mathcal{L}_{r l}
$$

**ç»“æœåˆ†æ:**

![image-20210204164236489](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210204164236489.png)

## [ArXiv 2020] MLR: A Two-stage Conversational Query Rewriting Model with Multi-task Learning (Song et  al.,  2020)

Paper Link: https://arxiv.org/abs/2004.05812

åœ¨è¯¥æ¨¡å‹ä¸­, è¯­å¥é‡å†™è¢«å®šä¹‰ä¸ºä¸€ä¸ªåºåˆ—ç”Ÿæˆé—®é¢˜ï¼Œå¹¶é€šè¿‡è¾…åŠ©çš„è¯ç±»æ ‡ç­¾(word category label)é¢„æµ‹ä»»åŠ¡å¼•å…¥è¯ç±»ä¿¡æ¯.

<img src="https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210204165134805.png" alt="image-20210204165134805" style="zoom:80%;" />

$$
L=L g+L c=-\sum_{i} \log p\left(y_{i}\right)-\sum_{j} \log p\left(c_{j}\right)
$$

å…¶ä¸­$p(y_{i})$æ˜¯ç›®æ ‡ç”Ÿæˆè¯çš„é¢„æµ‹æ¦‚ç‡, $p(c_{j})$æ˜¯è¯ç±»æ ‡ç­¾çš„é¢„æµ‹æ¦‚ç‡.