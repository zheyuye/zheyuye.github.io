---
title: 'Data Augmentation with CoDA'
date: 2021-03-19
permalink: /data_augmentation_with_coda
tags:
  - NLP
  - Data Augmentation
---

æ•°æ®å¢å¼º(Data Augmentation)æ–¹æ³•æˆåŠŸåœ°æ”¹è¿›äº†å¤§è§„æ¨¡åŸºäºç¥ç»ç½‘ç»œçš„æ¨¡å‹. ç„¶è€Œ,ç°æœ‰çš„å¤§å¤šæ•°ç ”ç©¶éƒ½æ˜¯é’ˆå¯¹è®¡ç®—æœºè§†è§‰(CV)ä»»åŠ¡.å›¾åƒæ•°æ®å¾—ä»¥äºå…¶æ„é€ çš„ç‰¹æ€§, å¯ä»¥ä½¿ç”¨å¯ä»¥ä½¿ç”¨å‰ªè£, ç¿»è½¬, ç¼©æ”¾ç­‰æ“ä½œæ¥æ‰©å¤§æ•°æ®é›†. è‡ªç„¶è¯­è¨€çš„ç¦»æ•£æ€§, è®©è¿™ç§**ä¿ç•™æ ‡ç­¾ç›‘ç£æ€§(label-preserving)**åŒæ—¶æœ‰åŠ©äºæ¨¡å‹æ³›åŒ–çš„ç®€å•è½¬æ¢åœ¨æ–‡æœ¬åºåˆ—ä¸Šå¼‚å¸¸å›°éš¾.  ä»æ¨¡å‹å±‚é¢æ¥è®²ï¼Œå·¨æ— éœ¸å¼çš„å¤§å‹é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ä¾é å¤§é‡çš„ç®—åŠ›, åœ¨æµ·é‡çš„æ— ç›‘ç£æ–‡æœ¬ä¸‹è¢«å–‚é£Ÿä»¥å…ˆéªŒçŸ¥è¯†. ä½†æ˜¯å½“å°†å…¶åº”ç”¨äºå°æ ·æœ¬æ•°æ®çš„ä¸‹æ¸¸ä»»åŠ¡æ—¶, å¾€å¾€ä¼šå› ä¸ºæ•°æ®ç¼ºå¤±æ— æ³•è¡¨ç°å‡ºå…¶åº”æœ‰çš„æ¨¡å‹èƒ½åŠ›. ä¸ºæ­¤Microsoft Dynamics 365 AIå’ŒUIUCåœ¨è¿™é¡¹å·¥ä½œä¸­æå‡ºäº†CoDAæ–¹æ¡ˆ, è¿›ä¸€æ­¥å¯»æ‰¾æœ‰æ•ˆçš„æ•°æ®å¢å¼ºç­–ç•¥.



Paper Title: *CoDA: Contrast-enhanced and Diversity-promoting Data Augmentation for Natural Language Understanding*

Paper Source: ICLR 2021

Paper Link: https://openreview.net/forum?id=Ozk9MrX1hvA



å¸¦ç€ä¸‹é¢ä¸‰ä¸ªé—®é¢˜, æˆ‘ä»¬æ¥æ¢³ç†ä¸€ä¸‹æ–‡ç« çš„æ€è·¯

> 1. What are some label-preserving transformations, that can be applied to text, to compose useful augmented samples?
> 2. Are these transformations complementary in nature, and can we find some strategies to consolidate them for producing more diverse augmented examples?
> 3. How can we incorporate the obtained augmented samples into the training process in an effective and principled manner?

## Background

### Data Augmentation

æ•°æ®å¢å¼ºä»æ¦‚å¿µä¸Šæ¥è¯´å°±æ˜¯ä¸€ä¸ªå¯¹åŸæœ‰æ•°æ®é›†åˆè¿›è¡Œæ•°æ®æ‰©å……çš„æ–¹æ³•, åŸæœ‰è®­ç»ƒæ•°æ®$\mathcal{D}$å¯ä»¥è¡¨ç¤ºä¸º:

$$
\mathcal{D}=\left\{\boldsymbol{x}_{i}, y_{i}\right\}_{i=1 \ldots N}
$$

é€šè¿‡æŸäº›label-preserving transformations, å¯ä»¥æ˜¯back-translation (Sennrich et al., 2016; Edunov et al., 2018; Xie et al., 2019), mixup (Guo et al., 2019), c-BERT (Wu et al., 2019)è½¬å˜æˆæ–°çš„è®­ç»ƒé›†åˆ:

$$
\mathcal{D}^{\prime}=\left\{\boldsymbol{x}_{i}^{\prime}, \boldsymbol{y}_{i}^{\prime}\right\}_{i=1 \ldots N}
$$

åŸºäºåŸæœ‰é›†åˆ$\mathcal{D}$å’Œå¢å¼ºé›†åˆ$\mathcal{D}^{\prime}$ï¼Œå»å­¦ä¹ å‚æ•°$p_{\theta}(\cdot)$:

$$
\theta^{*}=\underset{\theta}{\arg \min } \sum_{\left(\boldsymbol{x}_{i}, y_{i}\right) \in \mathcal{D}} \mathcal{L}\left(p_{\theta}\left(\boldsymbol{x}_{i}\right), y_{i}\right)+\sum_{\left(\boldsymbol{x}_{i}^{\prime}, y_{i}^{\prime}\right) \in \mathcal{D}^{\prime}} \mathcal{L}\left(p_{\theta}\left(\boldsymbol{x}_{i}^{\prime}\right), y_{i}^{\prime}\right)
$$

ä¸‹å›¾æ¦‚æ‹¬äº†å…ˆæœŸè®ºæ–‡å·¥ä½œæ€»ç»“çš„æ•°æ®å¢å¼ºæ–¹æ³•, ä¸»è¦æ˜¯å›è¯‘(Back-Translation), ä»¥åŠå¯¹æŠ—è®­ç»ƒ(Adversarial Training)è¿™ä¸¤ç§æ–¹æ³•ä»¥åŠå®ƒä»¬çš„stacking:

![image-20210319114327077](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210319114327077.png)

### Back Translation

Back-Translationä¸€å¼€å§‹æ˜¯ä¸€ç§å†™ä½œæŠ€å·§, ç”¨ä»¥å¢åŠ è¯­è¨€ä¸°å¯Œåº¦, ç›®å‰è¢«å¹¿æ³›åº”ç”¨äºæœºå™¨ç¿»è¯‘é¢†åŸŸ. BTéœ€è¦ä¸¤ä¸ªseq-to-seqæ¨¡å‹çš„æ”¯æŒ, ç¬¬ä¸€ä¸ªç”Ÿæˆæ¨¡å‹å¾—åˆ°source->target, ç¬¬äºŒä¸ªç”Ÿæˆæ¨¡å‹å°†targeté‡æ–°è¯‘å›source. å›è¯‘æ³•å…ˆåˆ©ç”¨tgt2srcç¿»è¯‘æ¨¡å‹å°†yç¿»è¯‘åˆ°$x^{\prime}$, ç”Ÿæˆpseudo-parallel data $(x^{\prime},y)$. å†åˆ©ç”¨ç”Ÿæˆçš„ä¼ªç¿»è¯‘å¯¹$(x^{\prime},y)$æ›´æ–°src2tgtç¿»è¯‘æ¨¡å‹. åœ¨æœºå™¨ç¿»è¯‘åœºæ™¯ä¸­, BTå……åˆ†åˆ©ç”¨äº†éå¹³è¡ŒåŒè¯­æ•°æ®, å¾ˆå¥½åœ°è§£å†³äº†å¹³è¡Œè¯­æ–™ä¸è¶³çš„é—®é¢˜. 

å°†tgt2srcä»¥åŠsrc2tgtä¸¤ä¸ªseq-to-seqæ¨¡å‹ä¸²è¡Œ, å°±å¯ä»¥å¾—åˆ°$x \rightarrow y \rightarrow x^{\prime}$:

$$
\boldsymbol{x}_{i}^{\prime}=\text { BackTrans }\left(\boldsymbol{x}_{i}\right)
$$

ä¾‹å¦‚hello(En)->Hallo(Ge)->Hi(En). è¿™å°±æ˜¯å°†BTä½œä¸ºæ•°æ®å¢å¼ºæŠ€æœ¯æŠ½ç¦», ç”¨äºæ–‡æœ¬åˆ†ç±»ç­‰éæœºå™¨ç¿»è¯‘åœºæ™¯çš„æ€è·¯. BTæŠ€å·§çš„æœºå™¨å­¦ä¹ è§£è¯»æ˜¯:**æ¨¡å‹åº”è¯¥å¯¹äºä¸åŒè¡¨è¾¾å½¢å¼ä½†åŒä¸€è¯­ä¹‰çš„æ–‡æœ¬å…·æœ‰ä¸å˜æ€§.** å› æ­¤, å›è¯‘è¿™ä¸€å¢å¼ºæŠ€æœ¯çš„æ•ˆæœä¸»è¦å–å†³äºç¿»è¯‘æ¨¡å‹çš„å¥½å(encoder + decoder).

åœ¨Fig. 1aä¸­, æ˜¯ä¸€ä¸ªç”¨è‹±å¾·ç¿»è¯‘åšæ•°æ®å¢å¼ºçš„ä¾‹å­. å¯¹äºæˆ‘ä»¬çš„ç›®æ ‡è®­ç»ƒå‚æ•°$p_{\theta}(\cdot)$, å¯ä»¥é€šè¿‡æœ€å°åŒ–$$
\mathcal{R}_{\mathrm{CS}}\left(p_{\theta}\left(\boldsymbol{x}_{i}\right), p_{\theta}\left(\boldsymbol{x}_{i}^{\prime}\right)\right)
$$çš„æ–¹å¼è¿›è¡Œæ­£åˆ™åŒ–, ä¿è¯å¯¹äº$(x, x^{\prime})$, $p_{\theta}\boldsymbol{x}_{i}$, $p_{\theta}\boldsymbol{x^{\prime}}_{i}$æœ‰ä¸€è‡´çš„æ¦‚ç‡è¾“å‡º. Loss Fucntioné€šå¸¸é‡‡ç”¨KLæ•£åº¦.

### Adversarial Training

å¯¹æŠ—è®­ç»ƒæ–¹æ³•è¢«ç”¨äºæ–‡æœ¬æ•°æ®æå‡æ¨¡å‹çš„é²æ£’æ€§. ä¸æ•°æ®å¢å¼ºæŠ€æœ¯ç›¸æ¯”ï¼Œå¯¹æŠ—è®­ç»ƒä¸éœ€è¦ä»»ä½•é¢å¤–çš„é¢†åŸŸçŸ¥è¯†. ç›¸å, å®ƒä¾èµ–äºæ¨¡å‹æœ¬èº«æ¥ç»™å‡ºå¯¹æŠ—æ€§æ ·æœ¬ï¼Œå³æ¨¡å‹æœ€æœ‰å¯èƒ½åšå‡ºä¸æ­£ç¡®é¢„æµ‹çš„æ ·æœ¬ã€‚ä¸æ•°æ®å¢å¼ºç±»ä¼¼ï¼Œå¯¹æŠ—æ€§è®­ç»ƒé€šå¸¸ä¹Ÿåˆ©ç”¨äº¤å‰ç†µå’ŒåŸºäºä¸€è‡´æ€§çš„ç›®æ ‡è¿›è¡Œè®­ç»ƒ.

ä¸‹é¢æ˜¯ä¸¤ä¸ªæœ€å¸¸ç”¨çš„å¯¹æŠ—è®­ç»ƒçš„loss:


$$
\begin{array}{c}
\mathcal{R}_{\mathrm{AT}}\left(\boldsymbol{x}_{i}, \tilde{\boldsymbol{x}}_{i}, y_{i}\right)=\mathcal{L}\left(p_{\theta}\left(\tilde{\boldsymbol{x}}_{i}\right), y_{i}\right), \text { s.t. }\left\|\tilde{\boldsymbol{x}}_{i}-\boldsymbol{x}_{i}\right\| \leq \epsilon \\
\mathcal{R}_{\mathrm{VAT}}\left(\boldsymbol{x}_{i}, \tilde{\boldsymbol{x}}_{i}\right)=\mathcal{R}_{\mathrm{CS}}\left(p_{\theta}\left(\tilde{\boldsymbol{x}}_{i}\right), p_{\theta}\left(\boldsymbol{x}_{i}\right)\right), \text { s.t. }\left\|\tilde{\boldsymbol{x}}_{i}-\boldsymbol{x}_{i}\right\| \leq \epsilon
\end{array}
$$

é€šå¸¸æƒ…å†µä¸‹å¯¹æŠ—æ ·æœ¬çš„è·å–æ²¡æœ‰closed-formï¼Œå¯ä»¥ä½¿ç”¨åŸºäºæ¨¡å‹æ¢¯åº¦ç›¸ä¼¼çš„è¿‘ä¼¼æ–¹å¼æ„é€ å¯¹æŠ—æ ·æœ¬:


$$
\hat{\boldsymbol{x}}_{i} \approx \boldsymbol{x}_{i}+\epsilon \frac{\boldsymbol{g}}{\|\boldsymbol{g}\|_{2}}, \text { where } \boldsymbol{g}=\nabla_{\boldsymbol{x}_{i}} \mathcal{L}\left(p_{\theta}\left(\boldsymbol{x}_{i}\right), y_{i}\right)
$$


## Diversity Promoting Consistency Training

æ— è®ºæ˜¯Data Augmentationè¿˜æ˜¯Adversarial Training, å…¶ä¸»è¦æ€è·¯éƒ½æ˜¯ä¸€è‡´çš„â€“æ‰¾åˆ°å·²æœ‰æ ·æœ¬çš„ç›¸ä¼¼æ ·æœ¬, åŸºäºæ ·æœ¬ä¸€è‡´æ€§æœ€å°åŒ–è®­ç»ƒç›®æ ‡. è¿™æ—¶å€™å›é¡¾æˆ‘ä»¬çš„ç¬¬äºŒä¸ªé—®é¢˜, å³è¿™äº›ä¸åŒçš„æ•°æ®å¢å¼ºæ–¹æ³•æ˜¯å¦æ˜¯ç­‰åŒçš„æˆ–è€…æ˜¯äº’è¡¥çš„? æˆ‘ä»¬æ—¶å€™æ˜¯å¦å¯ä»¥é€šè¿‡æ··åˆæ‰€æœ‰æ•°æ®å¢å¼ºæ–¹æ³•, æ¥æå‡æ¨¡å‹æ³›åŒ–èƒ½åŠ›å‘¢ï¼Ÿåœ¨CVé¢†åŸŸï¼Œç»“åˆä¸åŒçš„æ•°æ®å¢å¼ºæ“ä½œè¢«è¯æ˜å¯ä»¥äº§ç”Ÿæ›´å¤šæ ·åŒ–çš„å¢å¼ºç¤ºä¾‹. ç„¶è€Œç›¸åŒçš„æƒ…å†µåœ¨NLPåœºæ™¯ä¸‹å…¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºä¸€ä¸ªå¥å­çš„è¯­ä¹‰å¯ä»¥é€šè¿‡è½»å¾®çš„å¹²æ‰°è€Œå®Œå…¨äº§ç”Ÿç¿»å¤©è¦†åœ°çš„å˜åŒ–.

åŸºäºäº”ç§æ•°æ®å¢å¼ºæ–¹æ³•:

1. Back-translation
2. c-BERT word replacement
3. mixup
4. cutoff
5. Adversarial training

æœ¬æ–‡æå‡ºäº†å¤šç§æ··åˆæ•°æ®å¢å¼ºçš„æ–¹æ³•ï¼Œå¯¹äºæ ·æœ¬æ•°æ®$x$ä¿æŒå…¶label $y$ä¸€è‡´çš„æƒ…å†µä¸‹, ç”Ÿæˆå¢å¼ºæ•°æ® $x^{\prime}$, :å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![image-20210319132651862](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210319132651862.png)

**a) éšæœºç»„åˆ(Random combination)**, åœ¨æ¯ä¸€ä¸ªmini-batchä¸­ï¼Œ$x$è¢«ä¸€ä¸ªéšæœºçš„æ•°æ®å¢å¼ºæ–¹æ³•æ›¿æ¢ä¸º$x^{\prime}$

**(b) æ··åˆæ’å€¼(Mixup interpolation)**ï¼Œåœ¨ä¸€ä¸ªmini-batchä¸­çš„ä¸¤ä¸ªæ ·æœ¬ $x_i$å’Œ$x_j$. åŸºäºä¸¤ä¸ªæ ·æœ¬çš„embedding $e_i$å’Œ$e_j$è¿›è¡Œçº¿æ€§æ’å€¼:
$$
\boldsymbol{e}_{i}^{\prime}=a \boldsymbol{e}_{i}+(1-a) \boldsymbol{e}_{j}
$$
å…¶ä¸­$a$æ˜¯æ’å€¼è¶…å‚æ•°ï¼Œç¬¦åˆBetaåˆ†å¸ƒ

(c) **é¡ºåºå åŠ (Sequential stacking)**, æ ·æœ¬æ•°æ®$x$åœ¨ä¸€ç³»åˆ—è¿ç»­ä¸²è¡Œå åŠ çš„æ•°æ®å¢å¼ºæ–¹æ³•ä¸‹ç”Ÿæˆ$x^{\prime}$. ç”±äºæ–‡æœ¬æ•°æ®æœ¬èº«çš„ç¦»æ•£å‹, ä¸€äº›å †å é¡ºåºæ˜¯å¤©ç„¶ä¸å¯è¡Œçš„. æ¯”å¦‚ç»è¿‡å¯¹æŠ—è®­ç»ƒç”Ÿæˆçš„æ ·æœ¬, ä¸é€‚åˆç”¨ä½œå›ç¿»çš„è¾“å…¥æ•°æ®, åˆç†çš„å †å é¡ºåºå¦‚ä¸‹å›¾æ‰€ç¤º:

![image-20210319140848742](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210319140848742.png)

å³å¯¹äºè®­ç»ƒæ ·æœ¬$x_i, y_i$, ä¸Šé¢è¿™ç§å †å æ“ä½œçš„ä¸€è‡´æ€§è®­ç»ƒç›®æ ‡å¯ä»¥è¡¨ç¤ºä¸º:

$$
\begin{array}{c}
\boldsymbol{x}_{i}^{\prime}=\operatorname{Back} \operatorname{Trans}\left(\boldsymbol{x}_{i}\right), \hat{\boldsymbol{x}}_{i} \approx \operatorname{argmax}_{\tilde{\boldsymbol{x}}_{i}} \mathcal{R}_{\mathrm{AT}}\left(\boldsymbol{x}_{i}^{\prime}, \tilde{\boldsymbol{x}}_{i}, y_{i}\right) \\
\mathcal{L}_{\mathrm{consistency}}\left(\boldsymbol{x}_{i}, \hat{\boldsymbol{x}}_{i}, y_{i}\right)=\mathcal{L}\left(p_{\theta}\left(\boldsymbol{x}_{i}\right), y_{i}\right)+\alpha \mathcal{L}\left(p_{\theta}\left(\hat{\boldsymbol{x}}_{i}\right), y_{i}\right)+\beta \mathcal{R}_{\mathrm{CS}}\left(p_{\theta}\left(\boldsymbol{x}_{i}\right), p_{\theta}\left(\hat{\boldsymbol{x}}_{i}\right)\right)
\end{array}
$$

å³å…ˆç”¨$x_i$åšå›è¯‘å¾—åˆ°$x_i^{\prime}$ï¼Œåœ¨æ–°çš„è®­ç»ƒé›†åˆä¸­æ‰¾åˆ°æ¨¡å‹æœ€éš¾åˆ†è¾¨çš„å¯¹æŠ—æ ·æœ¬$\hat{x}$.   $\hat{x}$æ˜¯é€šè¿‡ä¸¤ç§ä¸åŒçš„label-preserving transformationsè·å¾—çš„ï¼Œå› æ­¤åœ¨æ•°æ®åˆ†å¸ƒä¸Šåç¦»$x_i$æ›´è¿œï¼Œåº”è¯¥æ¯”$x_i^{\prime}$æ›´å¤šæ ·åŒ–. ä¸­ç¬¬ä¸€é¡¹ä¸ºæ¨¡å‹è®­ç»ƒæœ¬èº«çš„äº¤å‰ç†µå‡½æ•°ï¼Œç¬¬äºŒé¡¹è¡¨ç¤ºå¯¹æŠ—æ€§æŸå¤±ï¼Œç¬¬ä¸‰é¡¹æ˜¯ä¸€è‡´æ€§æŸå¤±é¡¹, æ–‡ä¸­é‡‡ç”¨Jensen-Shannon divergence:

$$
\left.\mathcal{R}_{\mathrm{CS}}\left(p_{\theta}\left(\boldsymbol{x}_{i}\right), p_{\theta}\left(\hat{\boldsymbol{x}}_{i}\right)\right)=\frac{1}{2}\left(\operatorname{KL}\left(p_{\theta}\left(\boldsymbol{x}_{i}\right) \| M\right)+\operatorname{KL}\left(p_{\theta}\left(\hat{\boldsymbol{x}}_{i}\right)\right) \| M\right)\right)
$$

å…¶ä¸­$M=\left(p_{\theta}\left(\boldsymbol{x}_{i}\right)+p_{\theta}\left(\hat{\boldsymbol{x}}_{i}\right)\right) / 2$. 

##  Contrastive Regularization

ä¸Šè¿°Lossçš„å­¦ä¹ ç›®æ ‡éƒ½æ˜¯ä¿æŒ$x_i$å’Œ$x_i^{\prime}$é¢„æµ‹ç»“æœçš„ä¸€è‡´æ€§. ç„¶è€Œæ–‡ç« æå‡º, é™¤äº†å…³å¿ƒ$(x_i, x_i^{\prime})$, $(x_i^{\prime}, x_j), i\neq j$çš„å…³ç³»ä¹Ÿå€¼å¾—æˆ‘ä»¬è€ƒè™‘. å³åœ¨æ•°æ®è¡¨å¾å±‚é¢, å¢å¼ºæ•°æ®$ x_i^{\prime}$åº”è¯¥ç›´è§‚åœ°æ¥è¿‘äºå…¶åŸå§‹æ•°æ®$x_i$, åŒæ—¶ç›¸å¯¹è¿œç¦»å…¶ä»–æ•°æ®ç‚¹$x_j$. 

è¿™ä¸ªç›´è§‚çš„æƒ³æ³•è¡ç”Ÿå‡ºä¸€ä¸ªé¢å¤–çš„å¯¹æ¯”å­¦ä¹ (Contrastive  learning)ç›®æ ‡, å¦‚ä¸‹å›¾æ‰€ç¤º:

![image-20210319132736104](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210319132736104.png)

å¯¹æ¯”å­¦ä¹ å…ˆæœŸå·¥ä½œä¸­å‘ç°, é‡‡ç”¨large batch sizeèƒ½å¤Ÿè¾ƒå¥½åœ°æå‡è®­ç»ƒæœ‰æ•ˆæ€§, ä¸ºæ­¤CoDAå¼•å…¥äº†Memory bankæ¥å­˜å‚¨å†å²embeding, ä»è€Œä½¿å¾—**å¤§é‡è´Ÿæ ·æœ¬æ•°æ®**åœ¨è®­ç»ƒä¸­çš„å¼•å…¥æˆä¸ºå¯èƒ½. åŒæ—¶, ä¸ºäº†é¿å…encoderåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å˜åŒ–å¤ªå¿«(å¯èƒ½å¯¼è‡´embedingä¸ä¸€è‡´)ï¼Œè¿˜åœ¨ç®—æ³•ä¸­åŠ å…¥äº†åŸºäºåŠ¨é‡çš„momentum encoder module, åœ¨æ¯ä¸€æ­¥å‚æ•°æ›´æ–°é€»è¾‘è°ƒæ•´ä¸º

$$
\bar{\theta} \leftarrow \gamma \bar{\theta}+(1-\gamma) \theta
$$

å…¶ä¸­$\theta$, $\bar{\theta}$åˆ†åˆ«ä¸ºquery encoderå’Œkey encoderçš„å‚æ•°. å¯¹äºè®­ç»ƒæ ·æœ¬$x_i$ä»¥åŠå®ƒçš„å¢å¼ºæ ·æœ¬$x_i^{\prime}$å¯ä»¥å¾—åˆ°queryå’Œkeyçš„è¡¨å¾:

$$
\boldsymbol{q}{i}=f{\theta}\left(\boldsymbol{x}{i}\right), \quad \boldsymbol{q}{i} ({\prime}=f_{\theta}\left(\boldsymbol{x}_{i}){\prime}\right), \quad \boldsymbol{k}{i}=f{\bar{\theta}}\left(\boldsymbol{x}_{i}\right)
$$

å®ƒä»¬çš„å¯¹æŠ—å­¦ä¹ ç›®æ ‡å¯ä»¥å†™ä½œ:

$$
\begin{aligned}
\mathcal{R}_{\text {contrast }}\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{i}^{\prime}, \mathcal{M}\right) &=\mathcal{R}_{\mathrm{CT}}\left(\boldsymbol{q}_{i}, \boldsymbol{k}_{i}, \mathcal{M}\right)+\mathcal{R}_{\mathrm{CT}}\left(\boldsymbol{q}_{i}^{\prime}, \boldsymbol{k}_{i}, \mathcal{M}\right) \\
\mathcal{R}_{\mathrm{CT}}\left(\boldsymbol{q}_{i}, \boldsymbol{k}_{i}, \mathcal{M}\right) &=-\log \frac{\exp \left(\operatorname{sim}\left(\boldsymbol{q}_{i}, \boldsymbol{k}_{i}\right) / \tau\right)}{\sum_{\boldsymbol{k}_{j} \in \mathcal{M} \cup\left\{\boldsymbol{k}_{i}\right\}} \exp \left(\operatorname{sim}\left(\boldsymbol{q}_{i}, \boldsymbol{k}_{j}\right) / \tau\right)}
\end{aligned}
$$

å…¶ä¸­$\gamma$æ˜¯temperature, $\mathcal{M}$æ˜¯memory bank, $\operatorname{sim}(\cdot)$é€‰å–Cosine similarity.  ç¬¬ä¸€é¡¹$\mathcal{R}_{\mathrm{CT}}\left(\boldsymbol{q}_{i}, \boldsymbol{k}_{i}, \mathcal{M}\right)$åŸºäºåŸå§‹æ ·æœ¬è®¡ç®—è€Œæ¥, è¡¨ç¤ºself-contrastive loss; ç¬¬äºŒé¡¹$\mathcal{R}_{\mathrm{CT}}\left(\boldsymbol{q}_{i}^{\prime}, \boldsymbol{k}_{i}, \mathcal{M}\right)$ğŸ‘‰å¢å¼ºæ ·æœ¬$x_i^{\prime}$å¾—åˆ°, è¡¨ç¤ºaugment-contrastive loss. å…¶è¡¨è¾¾çš„æƒ³æ³•æ˜¾è€Œæ˜“è§â€“**åŸå§‹æ ·æœ¬å’Œå¢å¼ºæ ·æœ¬å¯¹ç›¸å¯¹äºmemory bankä¸­çš„è´Ÿæ ·æœ¬ï¼Œåœ¨å­¦ä¹ è¡¨å¾ç‰¹å¾æ—¶åº”ä¿æŒæ›´è¿‘çš„è·ç¦».**  è¿™ä¸ªlossä¸ºæˆ‘ä»¬æä¾›äº†global information, ä½¿å¾—æ•´ä¸ªè®­ç»ƒå¾—åˆ°äº†å®è§‚æ­£åˆ™åŒ–.

å°†local consistency loss ä¸ global contrastive lossæ•´åˆå, å¯ä»¥å¾—åˆ°CoDAæ¡†æ¶çš„æœ€ç»ˆç›®æ ‡å‡½æ•°:
$$
\theta^{*}=\operatorname{argmin}_{\theta} \sum_{\left(\boldsymbol{x}_{i}, y_{i}\right) \in \mathcal{D}} \mathcal{L}_{\text {consistency }}\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{i}^{\prime}, y_{i}\right)+\lambda \mathcal{R}_{\text {contrast }}\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{i}^{\prime}, \mathcal{M}\right)
$$

## Experiments

###  Combining Label-Preserving Transformations 

å•ä¸€æ•°æ®å¢å¼ºæ–¹æ³•

* æ‰€æœ‰æ•°æ®å¢å¼ºæ–¹æ³•éƒ½åœ¨RoBERTa-baseæ¨¡å‹åŸºç¡€ä¸Šå–å¾—äº†è¿›æ­¥ï¼Œè¯æ˜äº†åˆ©ç”¨Label-Preserving Transformations åœ¨NLUåœºæ™¯ä¸‹çš„æœ‰æ•ˆæ€§
* mixupå’Œc-BERTç›¸æ¯”, back-translation, cutoffå’Œadversarial trainingçš„å®è¯ç»“æœæ›´å¼º.

æ··åˆæ•°æ®å¢å¼ºæ–¹æ³•

* back-translation + adversarial trainingçš„é¡ºåºå †å æ–¹å¼æœ€æœ‰æ•ˆ(åº”ç”¨äºä»¥ä¸‹æ‰€æœ‰å®éªŒ)


![image-20210319132836410](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210319132836410.png)

### Contrastive Regularization Design

é€‰å–äº†ä¸åŒçš„temperatureä»¥åŠmemory bank sizeè¿›è¡Œå®éªŒ

![image-20210319151710976](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210319151710976.png)

###  GLUE Benchmark Evaluation

![image-20210319150803993](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210319150803993.png)

* åœ¨BLUEæ•°æ®é›†ä¸‹, CoDaåœ¨å‡ ä¹æ‰€æœ‰å­ä»»åŠ¡ä¸‹éƒ½è¡¨ç°å‡ºäº†æ¯”å…¶ä»–æ•°æ®å¢å¼ºæ–¹æ³•éƒ½ä¼˜ç§€çš„ç»“æœ.

* ç›¸æ¯”Roberta-large model, è¡¨ç°å‡ºäº†å¹³å‡2.2%çš„æå‡. 

### é¢å¤–å®éªŒåˆ†æ

å°æ ·æœ¬æ•°æ®å®éªŒ

![image-20210319152208951](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210319152208951.png)

å¯¹æŠ—ç›®æ ‡æœ‰æ•ˆæ€§

ä¸ºäº†ç ”ç©¶æ‰€æå‡ºçš„å¯¹æ¯”æ­£åˆ™åŒ–ç›®æ ‡çš„ä¸€èˆ¬é€‚ç”¨æ€§ï¼Œè¿›ä¸€æ­¥å°†å…¶åº”ç”¨äºä¸åŒçš„æ•°æ®å¢å¼ºæ–¹æ³•. ä½¿ç”¨RoBERTa-baseæ¨¡å‹å’ŒQNLIæ•°æ®é›†è¿›è¡Œè¿™ç»„å®éªŒ. 

![image-20210319152227906](https://zheyuye-image-1257819557.cos.ap-shanghai.myqcloud.com/img/image-20210319152227906.png)

å¯ä»¥è§‚å¯Ÿåˆ°ï¼Œåœ¨å¤šä¸ªæ•°æ®å¢å¼ºæ–¹æ³•ä¸‹, å¯¹æ¯”å­¦ä¹ ç›®æ ‡éƒ½èƒ½æœ‰æ•ˆæ¨¡å‹çš„æ€§èƒ½. è¿™è¿›ä¸€æ­¥éªŒè¯äº†å¯¹æŠ—è®­ç»ƒå¼•å…¥çš„å…¨å±€ä¿¡æ¯æœ‰åˆ©äºæ›´æœ‰æ•ˆåœ°åˆ©ç”¨å¢å¼ºæ ·æœ¬.